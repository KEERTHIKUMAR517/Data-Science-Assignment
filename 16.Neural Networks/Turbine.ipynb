{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18c6041e",
   "metadata": {},
   "source": [
    "# Import Necessary Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cb7173f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T07:56:47.532329Z",
     "start_time": "2021-12-19T07:56:47.139380Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa46a5c8",
   "metadata": {},
   "source": [
    "# 1.Data Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a37c3ce",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T07:58:41.069061Z",
     "start_time": "2021-12-19T07:58:40.991271Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.8594</td>\n",
       "      <td>1007.9</td>\n",
       "      <td>96.799</td>\n",
       "      <td>3.5000</td>\n",
       "      <td>19.663</td>\n",
       "      <td>1059.2</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.70</td>\n",
       "      <td>10.605</td>\n",
       "      <td>3.1547</td>\n",
       "      <td>82.722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.7850</td>\n",
       "      <td>1008.4</td>\n",
       "      <td>97.118</td>\n",
       "      <td>3.4998</td>\n",
       "      <td>19.728</td>\n",
       "      <td>1059.3</td>\n",
       "      <td>550.00</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.598</td>\n",
       "      <td>3.2363</td>\n",
       "      <td>82.776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6.8977</td>\n",
       "      <td>1008.8</td>\n",
       "      <td>95.939</td>\n",
       "      <td>3.4824</td>\n",
       "      <td>19.779</td>\n",
       "      <td>1059.4</td>\n",
       "      <td>549.87</td>\n",
       "      <td>114.71</td>\n",
       "      <td>10.601</td>\n",
       "      <td>3.2012</td>\n",
       "      <td>82.468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.0569</td>\n",
       "      <td>1009.2</td>\n",
       "      <td>95.249</td>\n",
       "      <td>3.4805</td>\n",
       "      <td>19.792</td>\n",
       "      <td>1059.6</td>\n",
       "      <td>549.99</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.606</td>\n",
       "      <td>3.1923</td>\n",
       "      <td>82.670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.3978</td>\n",
       "      <td>1009.7</td>\n",
       "      <td>95.150</td>\n",
       "      <td>3.4976</td>\n",
       "      <td>19.765</td>\n",
       "      <td>1059.7</td>\n",
       "      <td>549.98</td>\n",
       "      <td>114.72</td>\n",
       "      <td>10.612</td>\n",
       "      <td>3.2484</td>\n",
       "      <td>82.311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15034</th>\n",
       "      <td>9.0301</td>\n",
       "      <td>1005.6</td>\n",
       "      <td>98.460</td>\n",
       "      <td>3.5421</td>\n",
       "      <td>19.164</td>\n",
       "      <td>1049.7</td>\n",
       "      <td>546.21</td>\n",
       "      <td>111.61</td>\n",
       "      <td>10.400</td>\n",
       "      <td>4.5186</td>\n",
       "      <td>79.559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15035</th>\n",
       "      <td>7.8879</td>\n",
       "      <td>1005.9</td>\n",
       "      <td>99.093</td>\n",
       "      <td>3.5059</td>\n",
       "      <td>19.414</td>\n",
       "      <td>1046.3</td>\n",
       "      <td>543.22</td>\n",
       "      <td>111.78</td>\n",
       "      <td>10.433</td>\n",
       "      <td>4.8470</td>\n",
       "      <td>79.917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15036</th>\n",
       "      <td>7.2647</td>\n",
       "      <td>1006.3</td>\n",
       "      <td>99.496</td>\n",
       "      <td>3.4770</td>\n",
       "      <td>19.530</td>\n",
       "      <td>1037.7</td>\n",
       "      <td>537.32</td>\n",
       "      <td>110.19</td>\n",
       "      <td>10.483</td>\n",
       "      <td>7.9632</td>\n",
       "      <td>90.912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15037</th>\n",
       "      <td>7.0060</td>\n",
       "      <td>1006.8</td>\n",
       "      <td>99.008</td>\n",
       "      <td>3.4486</td>\n",
       "      <td>19.377</td>\n",
       "      <td>1043.2</td>\n",
       "      <td>541.24</td>\n",
       "      <td>110.74</td>\n",
       "      <td>10.533</td>\n",
       "      <td>6.2494</td>\n",
       "      <td>93.227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15038</th>\n",
       "      <td>6.9279</td>\n",
       "      <td>1007.2</td>\n",
       "      <td>97.533</td>\n",
       "      <td>3.4275</td>\n",
       "      <td>19.306</td>\n",
       "      <td>1049.9</td>\n",
       "      <td>545.85</td>\n",
       "      <td>111.58</td>\n",
       "      <td>10.583</td>\n",
       "      <td>4.9816</td>\n",
       "      <td>92.498</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15039 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           AT      AP      AH    AFDP    GTEP     TIT     TAT     TEY     CDP  \\\n",
       "0      6.8594  1007.9  96.799  3.5000  19.663  1059.2  550.00  114.70  10.605   \n",
       "1      6.7850  1008.4  97.118  3.4998  19.728  1059.3  550.00  114.72  10.598   \n",
       "2      6.8977  1008.8  95.939  3.4824  19.779  1059.4  549.87  114.71  10.601   \n",
       "3      7.0569  1009.2  95.249  3.4805  19.792  1059.6  549.99  114.72  10.606   \n",
       "4      7.3978  1009.7  95.150  3.4976  19.765  1059.7  549.98  114.72  10.612   \n",
       "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
       "15034  9.0301  1005.6  98.460  3.5421  19.164  1049.7  546.21  111.61  10.400   \n",
       "15035  7.8879  1005.9  99.093  3.5059  19.414  1046.3  543.22  111.78  10.433   \n",
       "15036  7.2647  1006.3  99.496  3.4770  19.530  1037.7  537.32  110.19  10.483   \n",
       "15037  7.0060  1006.8  99.008  3.4486  19.377  1043.2  541.24  110.74  10.533   \n",
       "15038  6.9279  1007.2  97.533  3.4275  19.306  1049.9  545.85  111.58  10.583   \n",
       "\n",
       "           CO     NOX  \n",
       "0      3.1547  82.722  \n",
       "1      3.2363  82.776  \n",
       "2      3.2012  82.468  \n",
       "3      3.1923  82.670  \n",
       "4      3.2484  82.311  \n",
       "...       ...     ...  \n",
       "15034  4.5186  79.559  \n",
       "15035  4.8470  79.917  \n",
       "15036  7.9632  90.912  \n",
       "15037  6.2494  93.227  \n",
       "15038  4.9816  92.498  \n",
       "\n",
       "[15039 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine = pd.read_csv('gas_turbines (1).csv')\n",
    "turbine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbfc7041",
   "metadata": {},
   "source": [
    "# Data Understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "863e2c45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:05:05.942700Z",
     "start_time": "2021-12-19T08:05:05.922754Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      float64\n",
       "AP      float64\n",
       "AH      float64\n",
       "AFDP    float64\n",
       "GTEP    float64\n",
       "TIT     float64\n",
       "TAT     float64\n",
       "TEY     float64\n",
       "CDP     float64\n",
       "CO      float64\n",
       "NOX     float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2517de47",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:05:32.114125Z",
     "start_time": "2021-12-19T08:05:32.095175Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AT      0\n",
       "AP      0\n",
       "AH      0\n",
       "AFDP    0\n",
       "GTEP    0\n",
       "TIT     0\n",
       "TAT     0\n",
       "TEY     0\n",
       "CDP     0\n",
       "CO      0\n",
       "NOX     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fa857cb8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:05:46.239144Z",
     "start_time": "2021-12-19T08:05:46.206232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AT</th>\n",
       "      <th>AP</th>\n",
       "      <th>AH</th>\n",
       "      <th>AFDP</th>\n",
       "      <th>GTEP</th>\n",
       "      <th>TIT</th>\n",
       "      <th>TAT</th>\n",
       "      <th>TEY</th>\n",
       "      <th>CDP</th>\n",
       "      <th>CO</th>\n",
       "      <th>NOX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AT</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.412953</td>\n",
       "      <td>-0.549432</td>\n",
       "      <td>-0.099333</td>\n",
       "      <td>-0.049103</td>\n",
       "      <td>0.093067</td>\n",
       "      <td>0.338569</td>\n",
       "      <td>-0.207495</td>\n",
       "      <td>-0.100705</td>\n",
       "      <td>-0.088588</td>\n",
       "      <td>-0.600006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AP</th>\n",
       "      <td>-0.412953</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.042573</td>\n",
       "      <td>0.040318</td>\n",
       "      <td>0.078575</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>-0.223479</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>0.131198</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.256744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AH</th>\n",
       "      <td>-0.549432</td>\n",
       "      <td>0.042573</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.119249</td>\n",
       "      <td>-0.202784</td>\n",
       "      <td>-0.247781</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>-0.110272</td>\n",
       "      <td>-0.182010</td>\n",
       "      <td>0.165505</td>\n",
       "      <td>0.143061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AFDP</th>\n",
       "      <td>-0.099333</td>\n",
       "      <td>0.040318</td>\n",
       "      <td>-0.119249</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.744251</td>\n",
       "      <td>0.627254</td>\n",
       "      <td>-0.571541</td>\n",
       "      <td>0.717995</td>\n",
       "      <td>0.727152</td>\n",
       "      <td>-0.334207</td>\n",
       "      <td>-0.037299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GTEP</th>\n",
       "      <td>-0.049103</td>\n",
       "      <td>0.078575</td>\n",
       "      <td>-0.202784</td>\n",
       "      <td>0.744251</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.874526</td>\n",
       "      <td>-0.756884</td>\n",
       "      <td>0.977042</td>\n",
       "      <td>0.993784</td>\n",
       "      <td>-0.508259</td>\n",
       "      <td>-0.208496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TIT</th>\n",
       "      <td>0.093067</td>\n",
       "      <td>0.029650</td>\n",
       "      <td>-0.247781</td>\n",
       "      <td>0.627254</td>\n",
       "      <td>0.874526</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.357320</td>\n",
       "      <td>0.891587</td>\n",
       "      <td>0.887238</td>\n",
       "      <td>-0.688272</td>\n",
       "      <td>-0.231636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TAT</th>\n",
       "      <td>0.338569</td>\n",
       "      <td>-0.223479</td>\n",
       "      <td>0.010859</td>\n",
       "      <td>-0.571541</td>\n",
       "      <td>-0.756884</td>\n",
       "      <td>-0.357320</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.720356</td>\n",
       "      <td>-0.744740</td>\n",
       "      <td>0.063404</td>\n",
       "      <td>0.009888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TEY</th>\n",
       "      <td>-0.207495</td>\n",
       "      <td>0.146939</td>\n",
       "      <td>-0.110272</td>\n",
       "      <td>0.717995</td>\n",
       "      <td>0.977042</td>\n",
       "      <td>0.891587</td>\n",
       "      <td>-0.720356</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>-0.541751</td>\n",
       "      <td>-0.102631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CDP</th>\n",
       "      <td>-0.100705</td>\n",
       "      <td>0.131198</td>\n",
       "      <td>-0.182010</td>\n",
       "      <td>0.727152</td>\n",
       "      <td>0.993784</td>\n",
       "      <td>0.887238</td>\n",
       "      <td>-0.744740</td>\n",
       "      <td>0.988473</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.520783</td>\n",
       "      <td>-0.169103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CO</th>\n",
       "      <td>-0.088588</td>\n",
       "      <td>0.041614</td>\n",
       "      <td>0.165505</td>\n",
       "      <td>-0.334207</td>\n",
       "      <td>-0.508259</td>\n",
       "      <td>-0.688272</td>\n",
       "      <td>0.063404</td>\n",
       "      <td>-0.541751</td>\n",
       "      <td>-0.520783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.316743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOX</th>\n",
       "      <td>-0.600006</td>\n",
       "      <td>0.256744</td>\n",
       "      <td>0.143061</td>\n",
       "      <td>-0.037299</td>\n",
       "      <td>-0.208496</td>\n",
       "      <td>-0.231636</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>-0.102631</td>\n",
       "      <td>-0.169103</td>\n",
       "      <td>0.316743</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            AT        AP        AH      AFDP      GTEP       TIT       TAT  \\\n",
       "AT    1.000000 -0.412953 -0.549432 -0.099333 -0.049103  0.093067  0.338569   \n",
       "AP   -0.412953  1.000000  0.042573  0.040318  0.078575  0.029650 -0.223479   \n",
       "AH   -0.549432  0.042573  1.000000 -0.119249 -0.202784 -0.247781  0.010859   \n",
       "AFDP -0.099333  0.040318 -0.119249  1.000000  0.744251  0.627254 -0.571541   \n",
       "GTEP -0.049103  0.078575 -0.202784  0.744251  1.000000  0.874526 -0.756884   \n",
       "TIT   0.093067  0.029650 -0.247781  0.627254  0.874526  1.000000 -0.357320   \n",
       "TAT   0.338569 -0.223479  0.010859 -0.571541 -0.756884 -0.357320  1.000000   \n",
       "TEY  -0.207495  0.146939 -0.110272  0.717995  0.977042  0.891587 -0.720356   \n",
       "CDP  -0.100705  0.131198 -0.182010  0.727152  0.993784  0.887238 -0.744740   \n",
       "CO   -0.088588  0.041614  0.165505 -0.334207 -0.508259 -0.688272  0.063404   \n",
       "NOX  -0.600006  0.256744  0.143061 -0.037299 -0.208496 -0.231636  0.009888   \n",
       "\n",
       "           TEY       CDP        CO       NOX  \n",
       "AT   -0.207495 -0.100705 -0.088588 -0.600006  \n",
       "AP    0.146939  0.131198  0.041614  0.256744  \n",
       "AH   -0.110272 -0.182010  0.165505  0.143061  \n",
       "AFDP  0.717995  0.727152 -0.334207 -0.037299  \n",
       "GTEP  0.977042  0.993784 -0.508259 -0.208496  \n",
       "TIT   0.891587  0.887238 -0.688272 -0.231636  \n",
       "TAT  -0.720356 -0.744740  0.063404  0.009888  \n",
       "TEY   1.000000  0.988473 -0.541751 -0.102631  \n",
       "CDP   0.988473  1.000000 -0.520783 -0.169103  \n",
       "CO   -0.541751 -0.520783  1.000000  0.316743  \n",
       "NOX  -0.102631 -0.169103  0.316743  1.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "turbine.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "801c2cd3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:08:15.441215Z",
     "start_time": "2021-12-19T08:08:14.126730Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.heatmap(turbine.corr(),annot=True,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "732f187f",
   "metadata": {},
   "source": [
    "# 3.Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "11ca1458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:15:07.441409Z",
     "start_time": "2021-12-19T08:15:07.424455Z"
    }
   },
   "outputs": [],
   "source": [
    "X = turbine.drop('TEY',axis = 1)\n",
    "y = turbine[['TEY']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "46379a9e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:15:45.954647Z",
     "start_time": "2021-12-19T08:15:45.934700Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "minmax = MinMaxScaler()\n",
    "X_scaled = minmax.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f55b4b01",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:16:41.067360Z",
     "start_time": "2021-12-19T08:16:41.055360Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X_scaled,y,random_state=12,test_size=.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0231cb12",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:16:54.020578Z",
     "start_time": "2021-12-19T08:16:54.014595Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((12031, 10), (12031, 1))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0f357f09",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:16:59.609658Z",
     "start_time": "2021-12-19T08:16:59.597681Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3008, 10), (3008, 1))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5ca0e89",
   "metadata": {},
   "source": [
    "# 4.Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d39f995",
   "metadata": {},
   "source": [
    "#### Build the Architechure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99441f46",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T08:18:26.982652Z",
     "start_time": "2021-12-19T08:18:26.974640Z"
    }
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "728f2c1a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:02:17.608574Z",
     "start_time": "2021-12-19T09:02:17.548700Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 100)               1100      \n",
      "                                                                 \n",
      " dropout_13 (Dropout)        (None, 100)               0         \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 60)                6060      \n",
      "                                                                 \n",
      " dropout_14 (Dropout)        (None, 60)                0         \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 60)                3660      \n",
      "                                                                 \n",
      " dropout_15 (Dropout)        (None, 60)                0         \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 1)                 61        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 10,881\n",
      "Trainable params: 10,881\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(units = 100,input_dim = 10,kernel_initializer = 'uniform' ,activation = 'relu'))\n",
    "model.add((Dropout(0.1)))\n",
    "model.add(Dense(units = 60,kernel_initializer = 'uniform',activation = 'relu'))\n",
    "model.add((Dropout(0.2)))\n",
    "model.add(Dense(units = 60,kernel_initializer = 'uniform',activation = 'relu'))\n",
    "model.add((Dropout(0.01)))\n",
    "model.add(Dense(units = 1,kernel_initializer = 'uniform',activation = 'linear'))\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d81d5",
   "metadata": {},
   "source": [
    "### Complie the architechure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a4b15cc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:02:21.437119Z",
     "start_time": "2021-12-19T09:02:21.420166Z"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',loss='mean_absolute_error', metrics='accuracy',)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ffc5069",
   "metadata": {},
   "source": [
    "# 5.Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "7a9993f3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:08:09.578632Z",
     "start_time": "2021-12-19T09:07:35.669566Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.9026 - accuracy: 0.0000e+00 - val_loss: 2.1752 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.9170 - accuracy: 0.0000e+00 - val_loss: 1.5986 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.7965 - accuracy: 0.0000e+00 - val_loss: 1.2373 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.8358 - accuracy: 0.0000e+00 - val_loss: 1.2071 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.8005 - accuracy: 0.0000e+00 - val_loss: 1.7898 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.7921 - accuracy: 0.0000e+00 - val_loss: 1.1413 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.7655 - accuracy: 0.0000e+00 - val_loss: 1.5319 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.6784 - accuracy: 0.0000e+00 - val_loss: 0.9331 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.7394 - accuracy: 0.0000e+00 - val_loss: 1.2775 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.6827 - accuracy: 0.0000e+00 - val_loss: 0.9519 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.6755 - accuracy: 0.0000e+00 - val_loss: 1.9568 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.6771 - accuracy: 0.0000e+00 - val_loss: 1.1185 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.7433 - accuracy: 0.0000e+00 - val_loss: 1.0873 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.7331 - accuracy: 0.0000e+00 - val_loss: 0.9787 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.6185 - accuracy: 0.0000e+00 - val_loss: 2.6344 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.6748 - accuracy: 0.0000e+00 - val_loss: 1.3027 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.7034 - accuracy: 0.0000e+00 - val_loss: 1.4712 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.6949 - accuracy: 0.0000e+00 - val_loss: 1.5043 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.6024 - accuracy: 0.0000e+00 - val_loss: 0.8877 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.6037 - accuracy: 0.0000e+00 - val_loss: 1.1528 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.5882 - accuracy: 0.0000e+00 - val_loss: 1.2761 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.5917 - accuracy: 0.0000e+00 - val_loss: 0.9057 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.5619 - accuracy: 0.0000e+00 - val_loss: 0.7974 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.5304 - accuracy: 0.0000e+00 - val_loss: 0.7153 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.5238 - accuracy: 0.0000e+00 - val_loss: 0.8321 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4868 - accuracy: 0.0000e+00 - val_loss: 2.5409 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4789 - accuracy: 0.0000e+00 - val_loss: 1.0895 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4611 - accuracy: 0.0000e+00 - val_loss: 1.3268 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4752 - accuracy: 0.0000e+00 - val_loss: 0.7593 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4447 - accuracy: 0.0000e+00 - val_loss: 1.0872 - val_accuracy: 0.0000e+00\n",
      "Epoch 31/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4900 - accuracy: 0.0000e+00 - val_loss: 1.7432 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.4495 - accuracy: 0.0000e+00 - val_loss: 0.8821 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4576 - accuracy: 0.0000e+00 - val_loss: 0.9034 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4770 - accuracy: 0.0000e+00 - val_loss: 0.7022 - val_accuracy: 0.0000e+00\n",
      "Epoch 35/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4076 - accuracy: 0.0000e+00 - val_loss: 1.1907 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.4414 - accuracy: 0.0000e+00 - val_loss: 2.2005 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.4573 - accuracy: 0.0000e+00 - val_loss: 0.7296 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4376 - accuracy: 0.0000e+00 - val_loss: 1.4876 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4132 - accuracy: 0.0000e+00 - val_loss: 1.2599 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.3842 - accuracy: 0.0000e+00 - val_loss: 3.1094 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.4295 - accuracy: 0.0000e+00 - val_loss: 2.9020 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4127 - accuracy: 0.0000e+00 - val_loss: 0.9367 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.4338 - accuracy: 0.0000e+00 - val_loss: 2.1824 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4130 - accuracy: 0.0000e+00 - val_loss: 2.9807 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4134 - accuracy: 0.0000e+00 - val_loss: 1.2563 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4182 - accuracy: 0.0000e+00 - val_loss: 1.3118 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.3799 - accuracy: 0.0000e+00 - val_loss: 2.2227 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.3730 - accuracy: 0.0000e+00 - val_loss: 0.7024 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/50\n",
      "422/422 [==============================] - 1s 2ms/step - loss: 2.4164 - accuracy: 0.0000e+00 - val_loss: 3.4268 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/50\n",
      "422/422 [==============================] - 1s 1ms/step - loss: 2.4212 - accuracy: 0.0000e+00 - val_loss: 2.4633 - val_accuracy: 0.0000e+00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b57e836e80>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train,batch_size=20,epochs=50,validation_split=.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "4466b407",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:03:01.942320Z",
     "start_time": "2021-12-19T09:03:01.565232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "376/376 [==============================] - 0s 843us/step - loss: 0.8398 - accuracy: 0.0000e+00\n",
      "Accuracy: 0.0\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_train, y_train)\n",
    "print('Accuracy:',(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0788d9a6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:07:27.379686Z",
     "start_time": "2021-12-19T09:07:27.372705Z"
    }
   },
   "source": [
    "#### Tuning of Hyperparameters :\n",
    "##### Hyperparameters all at once\n",
    "**The hyperparameter optimization was carried out by taking 2 hyperparameters at once. We may have missed the best values. The performance can be further improved by finding the optimum values of hyperparameters all at once given by the code snippet below.**\n",
    "#### This process is computationally expensive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "aad20172",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:18:33.372478Z",
     "start_time": "2021-12-19T09:18:33.355558Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the grid search parameters\n",
    "\n",
    "batch_size = [10,20,30]\n",
    "epochs = [10,50,100]\n",
    "learning_rate = [0.001,0.01,0.1]\n",
    "dropout_rate = [0.0,0.1,0.2]\n",
    "activation_function = ['softmax','relu','tanh','linear']\n",
    "init = ['uniform','normal','zero']\n",
    "neuron1 = [100,60,30]\n",
    "neuron2 = [80,60,25]\n",
    "\n",
    "param_grids = dict(batch_size = batch_size,epochs = epochs,learning_rate = learning_rate,dropout_rate = dropout_rate,\n",
    "                   activation_function = activation_function,init = init,neuron1 = neuron1,neuron2 = neuron2)\n",
    "\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d248863e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:18:13.059747Z",
     "start_time": "2021-12-19T09:18:13.052799Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_model(learning_rate,dropout_rate,activation_function,init,neuron1,neuron2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(neuron1,input_dim = 10,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(neuron2,input_dim = neuron1,kernel_initializer = init,activation = activation_function))\n",
    "    model.add(Dropout(dropout_rate))\n",
    "    model.add(Dense(1,activation = 'relu'))\n",
    "    \n",
    "    adam = Adam(lr = learning_rate)\n",
    "    model.compile(loss = 'mean_absolute_error',optimizer = adam,metrics = ['accuracy'])\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "a04ead7e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:18:14.630482Z",
     "start_time": "2021-12-19T09:18:14.620509Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create the model\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "model = KerasClassifier(build_fn = create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413e0307",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a6c348ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-12-19T09:58:47.593270Z",
     "start_time": "2021-12-19T09:19:24.444193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 8748 candidates, totalling 43740 fits\n",
      "[CV 1/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4773 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4750 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 969us/step - loss: 1587.4752 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 1587.4763 - accuracy: 8.3119e-05 0s - loss: 1590.4236 - accuracy: 0.\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1587.4758 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1587.4772 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1587.4768 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1587.4758 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1587.4747 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 807us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=80; total time=  12.8s\n",
      "[CV 2/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1724.5426 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 949us/step - loss: 1721.0197 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1717.9945 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1715.4674 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 863us/step - loss: 1713.0293 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 868us/step - loss: 1710.6189 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1708.2155 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1705.8188 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 872us/step - loss: 1703.4208 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1701.0267 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 832us/step - loss: 1349.0791 - accuracy: 0.0000e+00 0s - loss: 1411.8865 - accuracy: 0.0000e\n",
      "[CV 2/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=80; total time=  11.6s\n",
      "[CV 3/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1574.6368 - accuracy: 8.3119e-05A: 0s - loss: 1579.9532 - accuracy: 9.2081e\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6387 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6392 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6377 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 862us/step - loss: 1574.6390 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 871us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 869us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 859us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=80; total time=  12.4s\n",
      "[CV 4/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1605.1348 - accuracy: 1.6624e-04\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1601.6362 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1598.5573 - accuracy: 8.3119e-05A: 1s - loss: 1583.4949 - a - ETA: 0s - loss: 1596.7607 - accuracy: 9.2166e\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 1596.2943 - accuracy: 8.5543e-0 - 1s 1ms/step - loss: 1596.0249 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1593.5870 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1591.1759 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 1588.7733 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1586.3757 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1583.9783 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 884us/step - loss: 1581.5831 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 879us/step - loss: 1635.4462 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=80; total time=  12.6s\n",
      "[CV 5/5; 1/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1609.7179 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.2235 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1603.1517 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 930us/step - loss: 1600.6180 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 926us/step - loss: 1598.1782 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 989us/step - loss: 1595.7681 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 967us/step - loss: 1593.3647 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 941us/step - loss: 1590.9664 - accuracy: 8.3112e-05 0s - loss: 1589.9623 - accuracy: 0.00\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 901us/step - loss: 1588.5691 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 891us/step - loss: 1586.1760 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 837us/step - loss: 1408.7081 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 1/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=80; total time=  12.6s\n",
      "[CV 1/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1585.9081 - accuracy: 8.3119e-05A: 0s - loss: 1593.6908 - ac\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1582.5485 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 928us/step - loss: 1579.4185 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 986us/step - loss: 1576.8600 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 982us/step - loss: 1574.4177 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1572.0055 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1569.6021 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 964us/step - loss: 1567.2007 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 935us/step - loss: 1564.8041 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 982us/step - loss: 1562.4060 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 904us/step - loss: 1698.5259 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=60; total time=  12.7s\n",
      "[CV 2/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 923us/step - loss: 1724.5063 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1721.0546 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 854us/step - loss: 1718.0511 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 1715.5249 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 930us/step - loss: 1713.0907 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 982us/step - loss: 1710.6796 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1708.2784 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1705.8787 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 843us/step - loss: 1703.4827 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1701.0869 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 740us/step - loss: 1349.1466 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=60; total time=  11.6s\n",
      "[CV 3/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1573.0809 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1569.6356 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1566.6273 - accuracy: 8.3119e-05A: 1s - loss: 1568.2566 - accuracy: 0.00 - ETA: 0s - loss: 1570.0184 - accur - ETA: 0s - loss: 1559.7637 - accuracy: 9.1324e\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1564.1089 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 932us/step - loss: 1561.6764 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1559.2653 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 952us/step - loss: 1556.8655 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1554.4672 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1552.0698 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1549.6757 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 883us/step - loss: 1868.1217 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=60; total time=  12.8s\n",
      "[CV 4/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 972us/step - loss: 1605.1035 - accuracy: 1.6624e-04\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1601.7123 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1598.6198 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1596.0837 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1593.6448 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 846us/step - loss: 1591.2343 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1588.8308 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1586.4315 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1584.0336 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 990us/step - loss: 1581.6396 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 820us/step - loss: 1635.5045 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=60; total time=  12.1s\n",
      "[CV 5/5; 2/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 999us/step - loss: 1611.2385 - accuracy: 8.3112e-05 1s - loss: 1589.8564 - accuracy: 0.0000 - ETA: 0s - loss: 1619.6697 - ac\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2399 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 836us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1611.2397 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 954us/step - loss: 1611.2385 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2407 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1611.2389 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 966us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 2/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=60; total time=  12.9s\n",
      "[CV 1/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4762 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 988us/step - loss: 1587.4753 - accuracy: 8.3119e-05 1s - loss: 1584.7335 - accu\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 799us/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1587.4773 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 931us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 807us/step - loss: 1587.4768 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4773 - accuracy: 8.3119e-05A: 0s - loss: 1586.0267 - accurac\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4766 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 751us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=25; total time=  13.4s\n",
      "[CV 2/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1724.4445 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 897us/step - loss: 1721.0220 - accuracy: 8.3119e-05 1s - loss: 1767.9773 -\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 955us/step - loss: 1718.3330 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 958us/step - loss: 1715.8699 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1713.4463 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 981us/step - loss: 1711.0403 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1708.6394 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1706.2404 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 836us/step - loss: 1703.8428 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1701.4487 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 858us/step - loss: 1349.5029 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=25; total time=  12.3s\n",
      "[CV 3/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 839us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 872us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 884us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 849us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 753us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=25; total time=  11.9s\n",
      "[CV 4/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6511 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 857us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1606.6487 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 830us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 905us/step - loss: 1606.6500 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 925us/step - loss: 1606.6488 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1606.6488 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1606.6488 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 756us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=25; total time=  11.7s\n",
      "[CV 5/5; 3/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2400 - accuracy: 8.3112e-05A: 1s - loss: 1595.7770 - acc\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 908us/step - loss: 1611.2377 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 953us/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 933us/step - loss: 1611.2385 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 973us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 1611.2380 - accuracy: 8.3112e-05 0s - loss: 1608.1390 - accuracy: \n",
      "301/301 [==============================] - 0s 711us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 3/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=100, neuron2=25; total time=  12.9s\n",
      "[CV 1/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4773 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 962us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 860us/step - loss: 1587.4768 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 866us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1587.4779 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 907us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 820us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=80; total time=  12.0s\n",
      "[CV 2/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1724.5417 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1721.0669 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1717.9482 - accuracy: 8.3119e-05 0s - loss: 1722.2291 - accuracy: 0.\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 910us/step - loss: 1715.3976 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1712.9546 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1710.5427 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 865us/step - loss: 1708.1392 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 884us/step - loss: 1705.7408 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 845us/step - loss: 1703.3438 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 868us/step - loss: 1700.9491 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 835us/step - loss: 1349.0031 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=80; total time=  11.7s\n",
      "[CV 3/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1574.6382 - accuracy: 8.3119e-05A: 0s - loss: 1585.8966 - accurac\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 951us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1574.6385 - accuracy: 8.3119e-05 0s - loss: 1574.8960 - accuracy: 1.\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1574.6377 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 991us/step - loss: 1574.6368 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 1574.8312 - accuracy: 8.3752e-0 - 1s 948us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1574.6390 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 789us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=80; total time=  12.3s\n",
      "[CV 4/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6483 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6488 - accuracy: 8.3119e-05A: 0s - loss: 1612.8390 - accurac\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 967us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 934us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6493 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 854us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1606.6490 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 830us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=80; total time=  12.4s\n",
      "[CV 5/5; 4/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1609.7179 - accuracy: 0.0000e+00A: 0s - loss: 1605.6636 - acc\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.3059 - accuracy: 8.3112e-05A: 1s - loss: 1588.906\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 926us/step - loss: 1603.1737 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1600.5092 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1598.0436 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 974us/step - loss: 1595.6265 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 949us/step - loss: 1593.2223 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 945us/step - loss: 1590.8235 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1588.4280 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1586.0314 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 823us/step - loss: 1408.5615 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 4/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=80; total time=  12.2s\n",
      "[CV 1/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1585.9254 - accuracy: 1.6624e-04\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1582.5031 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1579.4302 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 987us/step - loss: 1576.8988 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.4613 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1572.0493 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1569.6456 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 953us/step - loss: 1567.2460 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1564.8481 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 906us/step - loss: 1562.4506 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 876us/step - loss: 1698.5728 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=60; total time=  12.6s\n",
      "[CV 2/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0571 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 929us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1726.0585 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1726.0570 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 881us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1000us/step - loss: 1726.0566 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1726.0580 - accuracy: 8.3119e-05 0s - loss: 1729.2990 - accuracy: 0.\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1726.0601 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 894us/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 787us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=60; total time=  12.1s\n",
      "[CV 3/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1573.0890 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1569.6312 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1566.6438 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 1564.1348 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 957us/step - loss: 1561.7018 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1559.2930 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1556.8909 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1554.4926 - accuracy: 8.3119e-05 0s - loss: 1576.2903 - accu\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1552.0964 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1549.7032 - accuracy: 8.3119e-05 0s - loss: 1568.4143 - accur\n",
      "301/301 [==============================] - 0s 791us/step - loss: 1868.1526 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=60; total time=  12.2s\n",
      "[CV 4/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6511 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6488 - accuracy: 8.3119e-05A: 0s - loss: 1609.9575 - accu\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 906us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 888us/step - loss: 1606.6488 - accuracy: 8.3119e-05 0s - loss: 1610.5061 - accura\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 872us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 846us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 860us/step - loss: 1606.6488 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 862us/step - loss: 1606.6500 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 822us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=60; total time=  11.7s\n",
      "[CV 5/5; 5/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 998us/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2385 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 990us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 997us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1611.2374 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 956us/step - loss: 1611.2380 - accuracy: 8.3112e-05 0s - loss: 1614.7660 - accuracy: 8.8574e-\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 899us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 918us/step - loss: 1611.2395 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 826us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 5/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=60; total time=  12.3s\n",
      "[CV 1/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4771 - accuracy: 8.3119e-05A: 0s - loss: 1583.2177 - accuracy: 0. - ETA: 0s - loss: 1585.1669 - accuracy: 1.011\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 988us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 910us/step - loss: 1587.4766 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 878us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 986us/step - loss: 1587.4753 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4768 - accuracy: 8.3119e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 839us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=25; total time=  12.1s\n",
      "[CV 2/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0592 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 916us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 859us/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 872us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 926us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0593 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0603 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0570 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 858us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=25; total time=  13.2s\n",
      "[CV 3/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1572.9929 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1569.6393 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1566.7917 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1564.2955 - accuracy: 8.3119e-05A: 0s - loss: 1548.4865 - \n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1561.8689 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1559.4615 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 971us/step - loss: 1557.0591 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 884us/step - loss: 1554.6621 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 2s 2ms/step - loss: 1552.2640 - accuracy: 8.3119e-05A: 0s - loss: 1552.6537 - accuracy: 8.5837e-\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1549.8694 - accuracy: 8.3119e-05A: 1s - loss: 1578\n",
      "301/301 [==============================] - 0s 937us/step - loss: 1868.3173 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=25; total time=  14.5s\n",
      "[CV 4/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1605.0085 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1601.6696 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1000us/step - loss: 1598.8206 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 907us/step - loss: 1596.3253 - accuracy: 8.3119e-05 0s - loss: 1590.5496 - accuracy: 1.043\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 967us/step - loss: 1593.8962 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1591.4885 - accuracy: 8.3119e-05 0s - loss: 1590.6833 - accuracy: 8.9445e-\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1589.0869 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1586.6859 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1584.2891 - accuracy: 8.3119e-05A: 1s - loss: 1589.9717 - accu - ETA: 0s - loss: 1583.1482 - accuracy: 9.2081e\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 972us/step - loss: 1581.8942 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 814us/step - loss: 1635.7565 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=25; total time=  13.3s\n",
      "[CV 5/5; 6/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1609.5261 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.3254 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 816us/step - loss: 1603.3723 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 838us/step - loss: 1600.8363 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 848us/step - loss: 1598.4025 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 892us/step - loss: 1595.9905 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1593.5884 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 867us/step - loss: 1591.1895 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1588.7924 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 836us/step - loss: 1586.3960 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 790us/step - loss: 1408.9301 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 6/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=60, neuron2=25; total time=  12.2s\n",
      "[CV 1/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4766 - accuracy: 8.3119e-05A: 0s - loss: 1597.8384 - accuracy: 0\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1587.4773 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1587.4755 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 905us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1587.4755 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 885us/step - loss: 1587.4758 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 874us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 908us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 751us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=80; total time=  11.5s\n",
      "[CV 2/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 822us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 855us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 901us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 853us/step - loss: 1726.0570 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 835us/step - loss: 1726.0597 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 741us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=80; total time=  11.1s\n",
      "[CV 3/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 1574.6368 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 809us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 949us/step - loss: 1574.6372 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 797us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 830us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 837us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 858us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 833us/step - loss: 1574.6372 - accuracy: 8.3119e-05 0s - loss: 1572.4276 - accuracy: 9.0744e-\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 843us/step - loss: 1574.6372 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 892us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=80; total time=  11.0s\n",
      "[CV 4/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 991us/step - loss: 1605.1434 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 939us/step - loss: 1601.7745 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 898us/step - loss: 1598.5298 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 925us/step - loss: 1595.9375 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 984us/step - loss: 1593.4857 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1591.0719 - accuracy: 8.3119e-05A: 0s - loss: 1584.0002 - ac\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 846us/step - loss: 1588.6680 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 811us/step - loss: 1586.2693 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 2s 2ms/step - loss: 1583.8735 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1581.4777 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 891us/step - loss: 1635.3317 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=80; total time=  13.0s\n",
      "[CV 5/5; 7/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1611.2385 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 954us/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 962us/step - loss: 1611.2374 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 869us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 886us/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 932us/step - loss: 1611.2385 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 920us/step - loss: 1611.2407 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 869us/step - loss: 1611.2397 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 719us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 7/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=80; total time=  11.8s\n",
      "[CV 1/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 956us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 812us/step - loss: 1587.4753 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 879us/step - loss: 1587.4773 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 928us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1587.4784 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 985us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 827us/step - loss: 1587.4766 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 876us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=60; total time=  11.6s\n",
      "[CV 2/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0587 - accuracy: 8.3119e-05A: 0s - loss: 1719.6837 - accuracy: 1. - ETA: 0s - loss: 1724.0940 - accuracy: 9.871\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0588 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0601 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 978us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0602 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 937us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 979us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 951us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 778us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=60; total time=  13.0s\n",
      "[CV 3/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1573.0980 - accuracy: 1.6624e-04\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 855us/step - loss: 1569.6641 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 878us/step - loss: 1566.6385 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 857us/step - loss: 1564.1134 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 859us/step - loss: 1561.6788 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 913us/step - loss: 1559.2676 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 972us/step - loss: 1556.8671 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 932us/step - loss: 1554.4691 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 972us/step - loss: 1552.0708 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 998us/step - loss: 1549.6764 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 768us/step - loss: 1868.1226 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=60; total time=  11.6s\n",
      "[CV 4/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1605.1111 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1601.7377 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1598.5896 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1596.0397 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1593.5988 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 993us/step - loss: 1591.1858 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1588.7833 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 954us/step - loss: 1586.3840 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1583.9866 - accuracy: 8.3119e-05A: 0s - loss: 1594.5786 - accuracy\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1581.5914 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 821us/step - loss: 1635.4553 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=60; total time=  13.2s\n",
      "[CV 5/5; 8/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2397 - accuracy: 8.3112e-05A: 0s - loss: 1613.2993 - accuracy: 9.970\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2389 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2375 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2390 - accuracy: 8.3112e-05A: 1s - loss: 1599.1641 - ac\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2391 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 844us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 8/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=60; total time=  16.6s\n",
      "[CV 1/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 995us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4773 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4758 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 993us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4758 - accuracy: 8.3119e-05A: 0s - loss: 1583.9614 - accuracy: 1.012\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4777 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 749us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=25; total time=  13.7s\n",
      "[CV 2/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1724.4396 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1721.1758 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1718.2502 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1715.7078 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1713.2687 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1710.8553 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 993us/step - loss: 1708.4521 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1706.0541 - accuracy: 8.3119e-05A: 0s - loss: 1710.6328 - accuracy\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1703.6576 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1701.2629 - accuracy: 8.3119e-05A: 0s - loss: 1702.9202 - accuracy: 9.1996e\n",
      "301/301 [==============================] - 0s 1ms/step - loss: 1349.3223 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=25; total time=  14.1s\n",
      "[CV 3/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1573.0291 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1569.6436 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1566.8524 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1564.3707 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1561.9463 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1559.5393 - accuracy: 8.3119e-05A: 0s - loss: 1558.6904 - accuracy: 1.0\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 2s 2ms/step - loss: 1557.1375 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1554.7378 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1552.3424 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1549.9478 - accuracy: 8.3119e-05A: 0s - loss: 1561.7882 - accuracy: 1.57 - ETA: 0s - loss: 1558.2546 - accuracy: 1.06\n",
      "301/301 [==============================] - 0s 741us/step - loss: 1868.3999 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=25; total time=  15.4s\n",
      "[CV 4/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 910us/step - loss: 1605.0421 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 847us/step - loss: 1601.7308 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1598.8157 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1596.3029 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 849us/step - loss: 1593.8691 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 998us/step - loss: 1591.4591 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 837us/step - loss: 1589.0575 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 817us/step - loss: 1586.6581 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 885us/step - loss: 1584.2605 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 1581.8658 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 818us/step - loss: 1635.7246 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=25; total time=  11.7s\n",
      "[CV 5/5; 9/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1609.5934 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 891us/step - loss: 1606.3452 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1603.4113 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1600.8934 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 913us/step - loss: 1598.4590 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 927us/step - loss: 1596.0483 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 998us/step - loss: 1593.6472 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 956us/step - loss: 1591.2483 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 829us/step - loss: 1588.8514 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 1586.4574 - accuracy: 8.3112e-05 0s - loss: 1578.9346 - accuracy: 0.00 - ETA: 0s - loss: 1585.0830 - accuracy: 8.3682e-0\n",
      "301/301 [==============================] - 0s 764us/step - loss: 1408.9852 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 9/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.001, neuron1=30, neuron2=25; total time=  11.9s\n",
      "[CV 1/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4768 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 984us/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 939us/step - loss: 1587.4766 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 918us/step - loss: 1587.4753 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 840us/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 920us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 729us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=80; total time=  12.2s\n",
      "[CV 2/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1710.8445 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 885us/step - loss: 1685.4777 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1661.7065 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1638.3079 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1615.1348 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1592.0757 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1569.1129 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1546.2969 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1523.7253 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1501.4508 - accuracy: 8.3119e-05A: 0s - loss: 1514.0370 - accuracy: 0\n",
      "301/301 [==============================] - 0s 797us/step - loss: 1133.1256 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=80; total time=  12.5s\n",
      "[CV 3/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1559.4968 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1534.1892 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 950us/step - loss: 1510.4819 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 958us/step - loss: 1487.1079 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 981us/step - loss: 1463.9578 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 958us/step - loss: 1440.9061 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 832us/step - loss: 1417.9426 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1395.1506 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1372.5375 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 997us/step - loss: 1350.1221 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 844us/step - loss: 1659.4025 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=80; total time=  12.3s\n",
      "[CV 4/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1591.2581 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 854us/step - loss: 1565.6875 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 972us/step - loss: 1541.9103 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 975us/step - loss: 1518.4359 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 962us/step - loss: 1495.1532 - accuracy: 8.3119e-05 1s - loss: 1547.2896 \n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 935us/step - loss: 1471.9611 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1448.9353 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 927us/step - loss: 1426.1227 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 881us/step - loss: 1403.6234 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 1381.9656 - accuracy: 8.3822e-0 - 1s 993us/step - loss: 1381.3817 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 925us/step - loss: 1424.9659 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=80; total time=  12.0s\n",
      "[CV 5/5; 10/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1596.0551 - accuracy: 8.3112e-05A: 0s - loss: 1596.0184 - accuracy: 8.8496e-\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 978us/step - loss: 1570.6948 - accuracy: 8.3112e-05 0s - loss: 1582.8746 - ac\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1546.8712 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1523.3535 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1499.9799 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1476.7311 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 964us/step - loss: 1453.6353 - accuracy: 8.3112e-05 0s - loss: 1453.1559 - accuracy:\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 965us/step - loss: 1430.8379 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 948us/step - loss: 1408.3140 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 975us/step - loss: 1386.0674 - accuracy: 8.3112e-05 0s - loss: 1389.5840 - accuracy: 1.\n",
      "301/301 [==============================] - 0s 880us/step - loss: 1202.6272 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 10/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=80; total time=  13.0s\n",
      "[CV 1/5; 11/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4758 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 949us/step - loss: 1587.4768 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 953us/step - loss: 1587.4747 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 933us/step - loss: 1587.4755 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 926us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 939us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4773 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 935us/step - loss: 1587.4763 - accuracy: 8.3119e-05 0s - loss: 1586.0626 - accuracy: 1.07\n",
      "301/301 [==============================] - 0s 855us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 11/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=60; total time=  12.2s\n",
      "[CV 2/5; 11/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1710.9319 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1685.6031 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1661.8292 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1638.4259 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 962us/step - loss: 1615.2584 - accuracy: 8.3119e-05 0s - loss: 1612.8792 - accuracy: 9.1996e\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 964us/step - loss: 1592.1942 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 981us/step - loss: 1569.2456 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1546.4410 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1523.8552 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1501.5579 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 968us/step - loss: 1133.2074 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 11/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=60; total time=  13.0s\n",
      "[CV 3/5; 11/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1559.6222 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 988us/step - loss: 1534.4078 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1510.6946 - accuracy: 8.3119e-05A: 0s - loss: 1502.3234 - accur\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1487.3118 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1464.1366 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 987us/step - loss: 1441.0688 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1418.1184 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 1395.3236 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 939us/step - loss: 1372.7104 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 1350.2866 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 846us/step - loss: 1659.5405 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 11/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=60; total time=  12.6s\n",
      "[CV 4/5; 11/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1591.4266 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1565.9932 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1542.2334 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 984us/step - loss: 1518.7847 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1495.4850 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1472.3109 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1449.2921 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1426.4841 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 958us/step - loss: 1403.9670 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1381.7170 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 901us/step - loss: 1425.3007 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 11/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=60; total time=  13.8s\n",
      "[CV 5/5; 11/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1596.2762 - accuracy: 8.3112e-05A: 1s - loss: 1598.7839 - a\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1571.0806 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 832us/step - loss: 1547.2644 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1523.7324 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 898us/step - loss: 1500.3632 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 944us/step - loss: 1477.1154 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1454.0426 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 937us/step - loss: 1431.2128 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 953us/step - loss: 1408.6779 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 935us/step - loss: 1386.4093 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 828us/step - loss: 1202.9535 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 11/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=60; total time=  12.4s\n",
      "[CV 1/5; 12/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1572.8579 - accuracy: 8.3119e-05A: 0s - loss: 1574.2787 - accuracy: 1.0\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 916us/step - loss: 1547.8414 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 995us/step - loss: 1524.0173 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1500.5510 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1477.2296 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1454.0129 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1430.9252 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1408.0332 - accuracy: 8.3119e-05A: 0s - loss: 1409.4827 - accuracy: 8.5179e-\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1385.3728 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1362.9760 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 831us/step - loss: 1493.1185 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 12/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=25; total time=  14.2s\n",
      "[CV 2/5; 12/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0593 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 866us/step - loss: 1726.0596 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 869us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 849us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 984us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 907us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1726.0571 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 768us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 12/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=25; total time=  11.6s\n",
      "[CV 3/5; 12/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 3s 991us/step - loss: 1560.1833 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1535.3257 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 881us/step - loss: 1511.6388 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 945us/step - loss: 1488.2712 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 953us/step - loss: 1465.1119 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 969us/step - loss: 1442.0492 - accuracy: 8.3119e-05 0s - loss: 1436.8678 - accura\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 841us/step - loss: 1419.1001 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 913us/step - loss: 1396.2969 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 951us/step - loss: 1373.6799 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 994us/step - loss: 1351.2377 - accuracy: 8.3119e-05 0s - loss: 1327.5079 - accuracy: - ETA: 0s - loss: 1342.4039 - accuracy: 1.1\n",
      "301/301 [==============================] - 0s 848us/step - loss: 1660.3907 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 12/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=25; total time=  13.5s\n",
      "[CV 4/5; 12/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 923us/step - loss: 1606.6488 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1606.6490 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 1606.6500 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 854us/step - loss: 1606.6497 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 811us/step - loss: 1606.6490 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 841us/step - loss: 1606.6509 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 854us/step - loss: 1606.6509 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 981us/step - loss: 1606.6503 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1606.6500 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 790us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 12/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=25; total time=  11.2s\n",
      "[CV 5/5; 12/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 990us/step - loss: 1596.7229 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1571.8102 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 858us/step - loss: 1548.0173 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 941us/step - loss: 1524.5272 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 847us/step - loss: 1501.1553 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 947us/step - loss: 1477.8848 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 884us/step - loss: 1454.7910 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 953us/step - loss: 1431.9606 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1409.4059 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 955us/step - loss: 1387.1635 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 760us/step - loss: 1203.7189 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 12/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=100, neuron2=25; total time=  11.9s\n",
      "[CV 1/5; 13/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1572.1447 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 937us/step - loss: 1546.6207 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1522.7592 - accuracy: 8.3119e-05 0s - loss: 1528.1597 - accuracy: 1.2\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 982us/step - loss: 1499.2621 - accuracy: 8.3119e-05 1s - loss: 1543.5679 -\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 956us/step - loss: 1475.9374 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 905us/step - loss: 1452.7435 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1429.6746 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1406.8016 - accuracy: 8.3119e-05 0s - loss: 1408.1694 - accuracy: 1.\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 937us/step - loss: 1384.1375 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 933us/step - loss: 1361.7677 - accuracy: 8.3119e-05 0s - loss: 1378.1206 - accura\n",
      "301/301 [==============================] - 0s 817us/step - loss: 1491.9752 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 13/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=80; total time=  12.1s\n",
      "[CV 2/5; 13/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1710.9259 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1685.6384 - accuracy: 8.3119e-05A: 0s - loss: 1692.1392 - accura\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 955us/step - loss: 1661.8755 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 929us/step - loss: 1638.4492 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 1615.2594 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1592.2166 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1569.2612 - accuracy: 8.3119e-05A: 0s - loss: 1579.4081 - accuracy:\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1546.4603 - accuracy: 8.3119e-05A: 0s - loss: 1542.5912 - accuracy:\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1523.8958 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1501.5961 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 761us/step - loss: 1133.2791 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 13/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=80; total time=  13.2s\n",
      "[CV 3/5; 13/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1559.4366 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1534.0739 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1510.3809 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1487.0061 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1463.8314 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1440.7778 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1417.8286 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1395.0339 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1372.4255 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1350.0297 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 951us/step - loss: 1659.2993 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 13/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=80; total time=  13.4s\n",
      "[CV 4/5; 13/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6510 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6498 - accuracy: 8.3119e-05A: 0s - loss: 1608.8462 - accuracy: 1.\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1606.6506 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1606.6509 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 688us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 13/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=80; total time=  13.3s\n",
      "[CV 5/5; 13/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 965us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2404 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 977us/step - loss: 1611.2389 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2394 - accuracy: 8.3112e-05A: 0s - loss: 1617.4521 - accuracy: 0\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 952us/step - loss: 1611.2397 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 898us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2395 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1611.2377 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 878us/step - loss: 1611.2397 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 739us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 13/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=80; total time=  12.6s\n",
      "[CV 1/5; 14/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1587.4773 - accuracy: 8.3119e-05 0s - loss: 1563.9026 - accu\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 797us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 865us/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 997us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 841us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 867us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 926us/step - loss: 1587.4745 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 916us/step - loss: 1587.4768 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 746us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 14/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=60; total time=  11.6s\n",
      "[CV 2/5; 14/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0574 - accuracy: 8.3119e-05A: 0s - loss: 1733.4319 - accuracy: 0.0000e+ - ETA: 0s - loss: 1731.6663 - accuracy: 0.00\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 966us/step - loss: 1726.0585 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 889us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 879us/step - loss: 1726.0582 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1726.0575 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 989us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 1726.0570 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 807us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 14/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=60; total time=  12.2s\n",
      "[CV 3/5; 14/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 979us/step - loss: 1574.6368 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1574.6372 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 839us/step - loss: 1574.6359 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 843us/step - loss: 1574.6395 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1574.6377 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 856us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 14/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=60; total time=  11.9s\n",
      "[CV 4/5; 14/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6493 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 1606.6493 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 908us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 844us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 836us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 874us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1606.6488 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1606.6497 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 886us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 14/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=60; total time=  11.7s\n",
      "[CV 5/5; 14/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1596.3590 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1571.2350 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1547.4363 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 966us/step - loss: 1523.9260 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1500.5553 - accuracy: 8.3112e-05A: 0s - loss: 1505.6619 - acc\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1477.3097 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 947us/step - loss: 1454.2209 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 899us/step - loss: 1431.3938 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1408.8645 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1386.6166 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 790us/step - loss: 1203.1692 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 14/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=60; total time=  12.3s\n",
      "[CV 1/5; 15/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1572.8781 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1547.8998 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1524.0833 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 906us/step - loss: 1500.6074 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 1477.2947 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 915us/step - loss: 1454.0831 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 1431.0029 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 845us/step - loss: 1408.1223 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 869us/step - loss: 1385.4609 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 905us/step - loss: 1363.0470 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 719us/step - loss: 1493.1893 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 15/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=25; total time=  11.6s\n",
      "[CV 2/5; 15/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1711.5365 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1686.6653 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1662.9299 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1639.5383 - accuracy: 8.3119e-05A: 0s - loss: 1638.0032 - accuracy: 8.4317e-0\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1616.3676 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 1593.2933 - accuracy: 8.3119e-05 0s - loss: 1588.9978 - acc\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1570.3447 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1547.5415 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1524.9359 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 934us/step - loss: 1502.6256 - accuracy: 8.3119e-05 0s - loss: 1500.7343 - accurac\n",
      "301/301 [==============================] - 0s 740us/step - loss: 1134.3690 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 15/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=25; total time=  12.8s\n",
      "[CV 3/5; 15/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 991us/step - loss: 1560.1764 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 958us/step - loss: 1535.3475 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 1511.6680 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 970us/step - loss: 1488.2982 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 857us/step - loss: 1465.1343 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 833us/step - loss: 1442.0858 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 879us/step - loss: 1419.1123 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1396.3268 - accuracy: 8.3119e-05 0s - loss: 1396.8588 - accuracy: 9.9206\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 835us/step - loss: 1373.7003 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 982us/step - loss: 1351.2784 - accuracy: 8.3119e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 750us/step - loss: 1660.4305 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 15/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=25; total time=  11.7s\n",
      "[CV 4/5; 15/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 950us/step - loss: 1606.6484 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 891us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 910us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 1607.7390 - accuracy: 8.4317e-0 - 1s 1ms/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 955us/step - loss: 1606.6511 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 828us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 15/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=25; total time=  12.0s\n",
      "[CV 5/5; 15/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 993us/step - loss: 1611.2397 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2379 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2399 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 988us/step - loss: 1611.2380 - accuracy: 8.3112e-05 0s - loss: 1603.1608 - accu\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2389 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 901us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 15/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=60, neuron2=25; total time=  13.2s\n",
      "[CV 1/5; 16/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1572.4023 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1547.1134 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 988us/step - loss: 1523.2655 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1499.8199 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1476.5067 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1453.2943 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 973us/step - loss: 1430.2367 - accuracy: 8.3119e-05 1s - loss: 1456.5568 \n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 863us/step - loss: 1407.3761 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1384.7122 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1362.3022 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 826us/step - loss: 1492.4751 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 16/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=80; total time=  12.6s\n",
      "[CV 2/5; 16/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 957us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0596 - accuracy: 8.3119e-05A: 0s - loss: 1735.8613 - accuracy\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0582 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0571 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 874us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 828us/step - loss: 1726.0593 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 862us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 765us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 16/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=80; total time=  13.6s\n",
      "[CV 3/5; 16/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1574.6368 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 830us/step - loss: 1574.6381 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 810us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 894us/step - loss: 1574.6373 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 866us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 885us/step - loss: 1574.6387 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 908us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 867us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 738us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 16/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=80; total time=  11.3s\n",
      "[CV 4/5; 16/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6509 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 852us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1606.6488 - accuracy: 8.3119e-05 0s - loss: 1609.2537 - accura\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 894us/step - loss: 1606.6510 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 841us/step - loss: 1606.6500 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 842us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 879us/step - loss: 1606.6484 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 872us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 765us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 16/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=80; total time=  11.4s\n",
      "[CV 5/5; 16/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1595.8658 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1570.3153 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1546.4700 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 915us/step - loss: 1522.9388 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1499.5754 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1476.3391 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1453.2676 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 872us/step - loss: 1430.4530 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 952us/step - loss: 1407.9335 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1385.6871 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 824us/step - loss: 1202.2574 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 16/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=80; total time=  11.7s\n",
      "[CV 1/5; 17/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4757 - accuracy: 8.3119e-05A: 0s - loss: 1587.6003 - accuracy: 8.5543e-0\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 1587.4777 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 905us/step - loss: 1587.4777 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 872us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 845us/step - loss: 1587.4762 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 933us/step - loss: 1587.4750 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 1587.4766 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 918us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 751us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 17/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=60; total time=  12.0s\n",
      "[CV 2/5; 17/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 986us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 962us/step - loss: 1726.0579 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1726.0597 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 929us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 915us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 823us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 17/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=60; total time=  12.3s\n",
      "[CV 3/5; 17/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 910us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1574.6364 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 908us/step - loss: 1574.6383 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 933us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 928us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 929us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 850us/step - loss: 1574.6390 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 827us/step - loss: 1574.6370 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 874us/step - loss: 1574.6373 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 757us/step - loss: 1894.2913 - accuracy: 0.0000e+00 0s - loss: 1126.8000 - accuracy: 0.0000e\n",
      "[CV 3/5; 17/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=60; total time=  11.4s\n",
      "[CV 4/5; 17/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1591.5565 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1566.2377 - accuracy: 8.3119e-05A: 0s - loss: 1567.5017 - accuracy: 1.\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1542.4779 - accuracy: 8.3119e-05A: 0s - loss: 1538.3364 - \n",
      "Epoch 4/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1519.0406 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 962us/step - loss: 1495.7488 - accuracy: 8.3119e-05 0s - loss: 1498.6343 - accurac\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1472.5692 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1449.5510 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 865us/step - loss: 1426.7501 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 847us/step - loss: 1404.2209 - accuracy: 8.3119e-05 0s - loss: 1407.4432 - accuracy: 9.2251e\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 923us/step - loss: 1381.9779 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 812us/step - loss: 1425.5634 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 17/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=60; total time=  12.2s\n",
      "[CV 5/5; 17/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 992us/step - loss: 1611.2389 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 797us/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 884us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 822us/step - loss: 1611.2374 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 1611.2374 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 862us/step - loss: 1611.2395 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 801us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 827us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 865us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 744us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 17/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=60; total time=  11.1s\n",
      "[CV 1/5; 18/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1572.8357 - accuracy: 8.3119e-05A: 0s - loss: 1580.6497 - accuracy: 1.1\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1547.8300 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1524.0179 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 817us/step - loss: 1500.5471 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1477.2167 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 853us/step - loss: 1454.0010 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 1430.9312 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 839us/step - loss: 1408.0607 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1385.4205 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 830us/step - loss: 1363.0095 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 725us/step - loss: 1493.1626 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 18/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=25; total time=  11.6s\n",
      "[CV 2/5; 18/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 955us/step - loss: 1726.0585 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0587 - accuracy: 8.3119e-05A: 1s - loss: 1731.6440 -\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 991us/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1726.0585 - accuracy: 8.3119e-05 0s - loss: 1722.3062 - accuracy: 9.0009e-\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 975us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 891us/step - loss: 1726.0579 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 830us/step - loss: 1726.0607 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 839us/step - loss: 1726.0592 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 882us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 18/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=25; total time=  11.8s\n",
      "[CV 3/5; 18/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 964us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 978us/step - loss: 1574.6381 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 954us/step - loss: 1574.6381 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1574.6372 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 858us/step - loss: 1574.6367 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 898us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 865us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 768us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 18/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=25; total time=  11.7s\n",
      "[CV 4/5; 18/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6505 - accuracy: 8.3119e-05A: 0s - loss: 1612.8342 - accuracy: 1.10\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6505 - accuracy: 8.3119e-05A: 0s - loss: 1606.9965 - \n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6488 - accuracy: 8.3119e-05A: 0s - loss: 1596.7864 - accuracy\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 961us/step - loss: 1606.6520 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 816us/step - loss: 1606.6500 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 914us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 855us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 823us/step - loss: 1606.6490 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 860us/step - loss: 1606.6484 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 745us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 18/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=25; total time=  11.7s\n",
      "[CV 5/5; 18/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 966us/step - loss: 1596.6663 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 987us/step - loss: 1571.6887 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 907us/step - loss: 1547.8962 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 825us/step - loss: 1524.3719 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 868us/step - loss: 1500.9917 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1477.7421 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 838us/step - loss: 1454.6576 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1431.8152 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1409.2611 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 940us/step - loss: 1387.0355 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 796us/step - loss: 1203.6268 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 18/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.01, neuron1=30, neuron2=25; total time=  11.5s\n",
      "[CV 1/5; 19/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4753 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1587.4762 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 961us/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4771 - accuracy: 8.3119e-05A: 0s - loss: 1592.7056 - accuracy: 1.040\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 841us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4767 - accuracy: 8.3119e-05A: 0s - loss: 1592.4850 - accur\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 778us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 19/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=80; total time=  12.2s\n",
      "[CV 2/5; 19/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1601.4648 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1386.5646 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1231.3081 - accuracy: 8.3119e-05A: 0s - loss: 1269.9580 - accuracy\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1110.9592 - accuracy: 8.3119e-05A: 0s - loss: 1127.8689 - accura\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 996.9506 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 930us/step - loss: 891.9617 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 797.8586 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 731.5564 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 896us/step - loss: 721.5312 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 896us/step - loss: 721.5378 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 792us/step - loss: 337.7487 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 19/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=80; total time=  12.5s\n",
      "[CV 3/5; 19/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1450.8013 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1241.2145 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 990us/step - loss: 1102.2008 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 967us/step - loss: 989.9615 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 878us/step - loss: 883.3681 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 977us/step - loss: 787.0498 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 928us/step - loss: 701.5513 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 892us/step - loss: 639.4523 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 901us/step - loss: 626.7773 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 626.7739 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 871us/step - loss: 737.3636 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 19/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=80; total time=  12.2s\n",
      "[CV 4/5; 19/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1482.4336 - accuracy: 8.3119e-05A: 0s - loss: 1549.8757 - ac\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1272.3417 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1122.8076 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1000.9460 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 885.4703 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 779.7017 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 965us/step - loss: 686.0746 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 945us/step - loss: 621.0266 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 915us/step - loss: 611.2283 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 922us/step - loss: 611.2340 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 794us/step - loss: 613.1855 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 19/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=80; total time=  12.9s\n",
      "[CV 5/5; 19/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1486.2101 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1276.3823 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1124.7028 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 992.1636 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 866.6708 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 751.6115 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 953us/step - loss: 653.2086 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 613.4344 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 886us/step - loss: 612.4062 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 612.4111 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 795us/step - loss: 629.7367 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 19/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=80; total time=  12.6s\n",
      "[CV 1/5; 20/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1463.5575 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1250.9734 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1098.5706 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 973.0535 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 853.4313 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 743.7001 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 867us/step - loss: 645.4565 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 842us/step - loss: 587.9305 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 925us/step - loss: 583.1515 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 981us/step - loss: 583.1564 - accuracy: 8.3119e-050s - loss: 584.4379 - accuracy - ETA: 0s - loss: 583.4605 - accuracy: 8.3612e-\n",
      "301/301 [==============================] - 0s 786us/step - loss: 805.2737 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 20/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=60; total time=  12.7s\n",
      "[CV 2/5; 20/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1602.1678 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 950us/step - loss: 1387.7601 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1232.2335 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1111.3560 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 857us/step - loss: 997.2867 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 833us/step - loss: 891.8093 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 862us/step - loss: 797.2833 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 858us/step - loss: 731.4335 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 721.5352 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 721.5438 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 741us/step - loss: 337.7869 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 20/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=60; total time=  11.4s\n",
      "[CV 3/5; 20/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 988us/step - loss: 1450.9022 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 981us/step - loss: 1241.1837 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 862us/step - loss: 1101.5981 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 841us/step - loss: 989.0276 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 883.0876 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 988us/step - loss: 786.8891 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 702.0485 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 812us/step - loss: 639.5236 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 813us/step - loss: 626.7828 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 838us/step - loss: 626.7753 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 864us/step - loss: 737.0046 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 20/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=60; total time=  11.6s\n",
      "[CV 4/5; 20/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6493 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 879us/step - loss: 1606.6509 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 920us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 888us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 898us/step - loss: 1606.6488 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 889us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 897us/step - loss: 1606.6514 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 727us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 20/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=60; total time=  11.6s\n",
      "[CV 5/5; 20/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1487.4631 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 860us/step - loss: 1278.2184 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 899us/step - loss: 1126.0282 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 934us/step - loss: 992.9678 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 867.4464 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 940us/step - loss: 752.0052 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 652.6782 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 613.2628 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 835us/step - loss: 612.4073 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 892us/step - loss: 612.4232 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 785us/step - loss: 629.7094 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 20/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=60; total time=  11.7s\n",
      "[CV 1/5; 21/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1464.1898 - accuracy: 8.3119e-05A: 0s - loss: 1517.2759 - accuracy:\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1251.8235 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1099.5895 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 940us/step - loss: 973.2656 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 853.3199 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 855us/step - loss: 744.2104 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 646.2150 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 588.0464 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 833us/step - loss: 583.1514 - accuracy: 8.3119e-050s - loss: 580.9187 - accuracy: 0.00\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 920us/step - loss: 583.1536 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 900us/step - loss: 805.2800 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 21/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=25; total time=  11.8s\n",
      "[CV 2/5; 21/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0593 - accuracy: 8.3119e-05A: 0s - loss: 1767.3798 - accuracy: 3. - ETA: 0s - loss: 1735.2358 - accuracy:\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 958us/step - loss: 1726.0601 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1726.0575 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 966us/step - loss: 1726.0579 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 934us/step - loss: 1726.0570 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 969us/step - loss: 1726.0593 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 975us/step - loss: 1726.0601 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 920us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 21/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=25; total time=  12.2s\n",
      "[CV 3/5; 21/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 980us/step - loss: 1453.7206 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 977us/step - loss: 1243.9160 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 987us/step - loss: 1104.0735 - accuracy: 8.3119e-05 0s - loss: 1106.0587 - accuracy: 8.7566e-\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 991.5136 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 884.9792 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 788.0386 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 907us/step - loss: 702.0781 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 862us/step - loss: 639.4090 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 899us/step - loss: 626.7869 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 626.7812 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 742us/step - loss: 737.2574 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 21/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=25; total time=  11.7s\n",
      "[CV 4/5; 21/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1484.6216 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 899us/step - loss: 1274.2794 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 1124.1050 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1002.4553 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 887.2781 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 781.2936 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 947us/step - loss: 686.3066 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 621.0800 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 830us/step - loss: 611.2273 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 885us/step - loss: 611.2341 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 770us/step - loss: 613.1246 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 21/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=25; total time=  11.5s\n",
      "[CV 5/5; 21/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2380 - accuracy: 8.3112e-05A: 0s - loss: 1616.4348 - accuracy: 0.0000e+0 - ETA: 0s - loss: 1615.6277 - accuracy: 0.\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 962us/step - loss: 1611.2400 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2379 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 976us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 975us/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 990us/step - loss: 1611.2391 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2377 - accuracy: 8.3112e-05A: 0s - loss: 1611.0979 - accuracy: 9.9900 - ETA: 0s - loss: 1611.2263 - accuracy: 8.3195e-0\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2394 - accuracy: 8.3112e-05A: 1s - loss: 1598.4772\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 978us/step - loss: 1611.2386 - accuracy: 8.3112e-05 0s - loss: 1602.0239 - accura\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 918us/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 839us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 21/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=100, neuron2=25; total time=  12.6s\n",
      "[CV 1/5; 22/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 944us/step - loss: 1587.4750 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 860us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 827us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 825us/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 894us/step - loss: 1587.4762 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 850us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 798us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 837us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 753us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 22/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=80; total time=  11.0s\n",
      "[CV 2/5; 22/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 956us/step - loss: 1726.0593 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1726.0601 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1726.0592 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 822us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 835us/step - loss: 1726.0575 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 932us/step - loss: 1726.0593 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 945us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 812us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 22/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=80; total time=  11.4s\n",
      "[CV 3/5; 22/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1574.6368 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 833us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 858us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 860us/step - loss: 1574.6372 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 892us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 844us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 886us/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 744us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 22/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=80; total time=  11.3s\n",
      "[CV 4/5; 22/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6488 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 961us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 970us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 933us/step - loss: 1606.6492 - accuracy: 8.3119e-05 0s - loss: 1608.4802 - accura\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1606.6488 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 891us/step - loss: 1606.6493 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 843us/step - loss: 1606.6519 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 816us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 722us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 22/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=80; total time=  11.9s\n",
      "[CV 5/5; 22/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2390 - accuracy: 8.3112e-05A: 0s - loss: 1600.4568 - accuracy - ETA: 0s - loss: 1606.2479 - accuracy: 9.6154\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 928us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 925us/step - loss: 1611.2377 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 852us/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 911us/step - loss: 1611.2397 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 872us/step - loss: 1611.2402 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 879us/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 886us/step - loss: 1611.2389 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 918us/step - loss: 1611.2379 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 831us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 22/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=80; total time=  11.6s\n",
      "[CV 1/5; 23/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 920us/step - loss: 1587.4753 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 852us/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1587.4772 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1587.4762 - accuracy: 8.3119e-05 0s - loss: 1591.8411 - accuracy: 1\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 1587.4768 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 862us/step - loss: 1587.4755 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 888us/step - loss: 1587.4766 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 888us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 23/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=60; total time=  11.4s\n",
      "[CV 2/5; 23/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 838us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 846us/step - loss: 1726.0585 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 849us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 897us/step - loss: 1726.0574 - accuracy: 8.3119e-05 0s - loss: 1724.2140 - accuracy: 0\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 824us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 852us/step - loss: 1726.0588 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 977us/step - loss: 1726.0570 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 821us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 23/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=60; total time=  11.4s\n",
      "[CV 3/5; 23/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 968us/step - loss: 1574.6378 - accuracy: 8.3119e-05 0s - loss: 1571.2136 - accuracy: 1.071\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 819us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 798us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 799us/step - loss: 1574.6392 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 854us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 809us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 831us/step - loss: 1574.6392 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1574.6381 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 858us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1574.6368 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 816us/step - loss: 1894.2913 - accuracy: 0.0000e+00 0s - loss: 1803.2196 - accuracy: 0.0000e+0\n",
      "[CV 3/5; 23/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=60; total time=  11.0s\n",
      "[CV 4/5; 23/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 971us/step - loss: 1483.4917 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1272.8271 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 810us/step - loss: 1123.4995 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 1001.6799 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 886.7664 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 836us/step - loss: 780.9651 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 814us/step - loss: 686.5327 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 939us/step - loss: 621.2281 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 969us/step - loss: 611.2322 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 954us/step - loss: 611.2314 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 2s 761us/step - loss: 613.1050 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 23/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=60; total time=  12.7s\n",
      "[CV 5/5; 23/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2391 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 828us/step - loss: 1611.2400 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 809us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1611.2374 - accuracy: 8.3112e-05 0s - loss: 1615.9656 - accuracy: \n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 835us/step - loss: 1611.2382 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 841us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 872us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 899us/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 913us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 823us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 23/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=60; total time=  11.3s\n",
      "[CV 1/5; 24/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 807us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 797us/step - loss: 1587.4750 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 822us/step - loss: 1587.4752 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1587.4777 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 879us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 827us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 874us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 888us/step - loss: 1587.4772 - accuracy: 8.3119e-05 0s - loss: 1585.5728 - accuracy: 1.2\n",
      "301/301 [==============================] - 0s 770us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 24/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=25; total time=  11.1s\n",
      "[CV 2/5; 24/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 981us/step - loss: 1603.2308 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 954us/step - loss: 1388.5348 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 973us/step - loss: 1232.9167 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1112.3990 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 997.9279 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 967us/step - loss: 892.4827 - accuracy: 8.3119e-050s - loss: 913.1\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 798.1943 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 731.9180 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 986us/step - loss: 721.5504 - accuracy: 8.3119e-050s - loss: 721.3650 - accuracy: 8.3542e-\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 982us/step - loss: 721.5415 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 946us/step - loss: 337.4486 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 24/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=25; total time=  12.6s\n",
      "[CV 3/5; 24/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 920us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 907us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 853us/step - loss: 1574.6381 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 867us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 872us/step - loss: 1574.6368 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 853us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 998us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1574.6365 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 832us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 24/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=25; total time=  11.5s\n",
      "[CV 4/5; 24/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 795us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 860us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1606.6493 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 894us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 866us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 945us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 940us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 1606.6497 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 818us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 24/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=25; total time=  11.6s\n",
      "[CV 5/5; 24/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1489.5470 - accuracy: 8.3112e-05A: 0s - loss: 1565.1670 - a\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 845us/step - loss: 1280.5972 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1128.3538 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 941us/step - loss: 995.2036 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 869.2392 - accuracy: 8.3112e-050s - loss: 878.9608 - accuracy: 9.\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 753.8170 - accuracy: 8.3112e-050s - loss:\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 989us/step - loss: 654.0746 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 863us/step - loss: 613.3050 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 884us/step - loss: 612.4074 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 612.4143 - accuracy: 8.3112e-05: \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "301/301 [==============================] - 0s 745us/step - loss: 629.8666 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 24/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=60, neuron2=25; total time=  11.9s\n",
      "[CV 1/5; 25/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 952us/step - loss: 1463.4692 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 862us/step - loss: 1251.2896 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 810us/step - loss: 1099.4016 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 974.3608 - accuracy: 8.6059e- - 1s 789us/step - loss: 973.0223 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 849us/step - loss: 853.1410 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 878us/step - loss: 743.2311 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 846us/step - loss: 645.5755 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 871us/step - loss: 587.8855 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 583.1567 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 869us/step - loss: 583.1544 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 801us/step - loss: 805.3026 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 25/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=80; total time=  11.0s\n",
      "[CV 2/5; 25/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 963us/step - loss: 1726.0575 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 852us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 860us/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1726.0593 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 874us/step - loss: 1726.0592 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 958us/step - loss: 1726.0577 - accuracy: 8.3119e-05 0s - loss: 1755.6685 - \n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 969us/step - loss: 1726.0566 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 937us/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 772us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 25/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=80; total time=  11.7s\n",
      "[CV 3/5; 25/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1449.9700 - accuracy: 8.3119e-05A: 0s - loss: 1483.7209 - accuracy: 1.\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1239.6534 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1101.1874 - accuracy: 8.3119e-05A: 0s - loss: 1126.5613 - accuracy: \n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 988.7601 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 931us/step - loss: 881.9821 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 807us/step - loss: 785.8148 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 830us/step - loss: 700.4602 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 865us/step - loss: 638.8813 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 626.7833 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 841us/step - loss: 626.7731 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 788us/step - loss: 737.2909 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 25/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=80; total time=  11.9s\n",
      "[CV 4/5; 25/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1606.6487 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 822us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 920us/step - loss: 1606.6503 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 934us/step - loss: 1606.6490 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 918us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 907us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 918us/step - loss: 1606.6503 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 779us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 25/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=80; total time=  11.7s\n",
      "[CV 5/5; 25/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 950us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 899us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 867us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 905us/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1611.2389 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 838us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 771us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 25/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=80; total time=  11.7s\n",
      "[CV 1/5; 26/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4768 - accuracy: 8.3119e-05A: 0s - loss: 1586.3303 - accu\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 957us/step - loss: 1587.4766 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 886us/step - loss: 1587.4757 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 816us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1587.4763 - accuracy: 8.3119e-05 0s - loss: 1600.8948 - accur\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 920us/step - loss: 1587.4753 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 952us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1587.4773 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 994us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 834us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 26/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=60; total time=  12.0s\n",
      "[CV 2/5; 26/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0598 - accuracy: 8.3119e-05A: 0s - loss: 1736.5330 - \n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0570 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 1724.0316 - accuracy: 8.6505e-0 - 1s 1ms/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 927us/step - loss: 1726.0588 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 844us/step - loss: 1726.0597 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 961us/step - loss: 1726.0574 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 989us/step - loss: 1726.0588 - accuracy: 8.3119e-05 0s - loss: 1715.9697 - accuracy: 0\n",
      "301/301 [==============================] - 0s 740us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 26/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=60; total time=  12.4s\n",
      "[CV 3/5; 26/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 978us/step - loss: 1452.2687 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 868us/step - loss: 1242.1042 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 826us/step - loss: 1102.5013 - accuracy: 8.3119e-05 0s - loss: 1122.2006 - ac\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 832us/step - loss: 990.2039 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 827us/step - loss: 883.3259 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 786.1032 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 842us/step - loss: 700.9330 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 639.5105 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 831us/step - loss: 626.7836 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 815us/step - loss: 626.7822 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 739us/step - loss: 737.1864 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 26/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=60; total time=  11.0s\n",
      "[CV 4/5; 26/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 978us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 832us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 814us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 823us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 852us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 888us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 885us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 795us/step - loss: 1606.6487 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 802us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 757us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 26/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=60; total time=  11.0s\n",
      "[CV 5/5; 26/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 966us/step - loss: 1611.2384 - accuracy: 8.3112e-05 0s - loss: 1612.8285 - accuracy: 1.058\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1611.2379 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 838us/step - loss: 1611.2407 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 837us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 854us/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 838us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1611.2397 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 748us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 26/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=60; total time=  11.3s\n",
      "[CV 1/5; 27/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 954us/step - loss: 1464.6294 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 779us/step - loss: 1252.2419 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 784us/step - loss: 1099.7805 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 788us/step - loss: 973.9792 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 867us/step - loss: 854.3896 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 846us/step - loss: 745.4394 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 830us/step - loss: 647.0709 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 588.2576 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 583.1528 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 583.1522 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 782us/step - loss: 805.3104 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 27/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=25; total time=  11.0s\n",
      "[CV 2/5; 27/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 891us/step - loss: 1604.1902 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1390.0421 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 928us/step - loss: 1233.7107 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 1112.8391 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 857us/step - loss: 998.7154 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 815us/step - loss: 893.8914 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 812us/step - loss: 799.6950 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 732.7935 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 845us/step - loss: 721.5476 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 835us/step - loss: 721.5356 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 739us/step - loss: 337.9253 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 27/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=25; total time=  11.0s\n",
      "[CV 3/5; 27/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 925us/step - loss: 1574.6368 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 809us/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 871us/step - loss: 1574.6367 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 944us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 950us/step - loss: 1574.6377 - accuracy: 8.3119e-05 0s - loss: 1578.7461 - ac\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1574.6373 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 925us/step - loss: 1574.6370 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 989us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 837us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 27/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=25; total time=  11.6s\n",
      "[CV 4/5; 27/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 976us/step - loss: 1606.6493 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 977us/step - loss: 1606.6493 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 941us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 941us/step - loss: 1606.6511 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 1606.6510 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 841us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1606.6490 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1606.6500 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1606.6510 - accuracy: 8.3119e-05 0s - loss: 1604.0070 - accuracy: 0.000\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 940us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 917us/step - loss: 1661.7108 - accuracy: 0.0000e+00 0s - loss: 1731.5442 - accuracy: 0.0000e+\n",
      "[CV 4/5; 27/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=25; total time=  11.8s\n",
      "[CV 5/5; 27/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1489.1669 - accuracy: 8.3112e-05A: 0s - loss: 1564.2885 - \n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1280.8481 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1128.8695 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 845us/step - loss: 995.4561 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 869.4144 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 826us/step - loss: 753.8948 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 866us/step - loss: 653.7787 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 817us/step - loss: 613.3392 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 612.4000 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 612.4172 - accuracy: 8.3112e-050s - loss: 610.9675 - accuracy\n",
      "301/301 [==============================] - 0s 881us/step - loss: 629.5308 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 27/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=uniform, learning_rate=0.1, neuron1=30, neuron2=25; total time=  11.7s\n",
      "[CV 1/5; 28/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4750 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 989us/step - loss: 1587.4753 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 986us/step - loss: 1587.4755 - accuracy: 8.3119e-05 0s - loss: 1585.4650 - accuracy: 8.6430e-\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 927us/step - loss: 1587.4772 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 922us/step - loss: 1587.4777 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1587.4750 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 795us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 28/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=80; total time=  12.8s\n",
      "[CV 2/5; 28/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1724.5253 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1721.0388 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 947us/step - loss: 1718.0137 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1715.4955 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 928us/step - loss: 1713.0613 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1710.6505 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1708.2463 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 853us/step - loss: 1705.8501 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 897us/step - loss: 1703.4524 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1701.0581 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 812us/step - loss: 1349.1088 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 28/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=80; total time=  12.2s\n",
      "[CV 3/5; 28/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1574.6382 - accuracy: 8.3119e-05A: 0s - loss: 1567.0909 - accuracy: 1.153 - ETA: 0s - loss: 1572.8053 - accuracy: 9.1996e\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6390 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 950us/step - loss: 1574.6381 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1574.6387 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1574.6381 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 878us/step - loss: 1574.6372 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 855us/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 857us/step - loss: 1574.6382 - accuracy: 8.3119e-05 0s - loss: 1574.2773 - accuracy\n",
      "301/301 [==============================] - 0s 772us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 28/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=80; total time=  11.7s\n",
      "[CV 4/5; 28/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 1605.1179 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 967us/step - loss: 1601.6895 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 957us/step - loss: 1598.5685 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 998us/step - loss: 1595.9756 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1593.5253 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1591.1096 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 1588.7081 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 913us/step - loss: 1586.3074 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 983us/step - loss: 1583.9110 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 972us/step - loss: 1581.5148 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 820us/step - loss: 1635.3767 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 28/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=80; total time=  12.1s\n",
      "[CV 5/5; 28/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1609.7072 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.2522 - accuracy: 8.3112e-05A: 1s - loss: 1608.95\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1603.1478 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1600.6063 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 885us/step - loss: 1598.1653 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 939us/step - loss: 1595.7540 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 982us/step - loss: 1593.3529 - accuracy: 8.3112e-05 0s - loss: 1590.5626 - accura\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 972us/step - loss: 1590.9541 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 918us/step - loss: 1588.5559 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 884us/step - loss: 1586.1624 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 893us/step - loss: 1408.6879 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 28/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=80; total time=  12.3s\n",
      "[CV 1/5; 29/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1585.9050 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1582.5258 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1579.5448 - accuracy: 8.3119e-05A: 0s - loss: 1576.5149 - accuracy: 0. - ETA: 0s - loss: 1577.8292 - accuracy: 8.7873e-\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1576.8990 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.4366 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1572.0184 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1569.6141 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1567.2148 - accuracy: 8.3119e-05A: 0s - loss: 1562.4417 - accuracy: 1.0\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1564.8152 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1562.4182 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 829us/step - loss: 1698.5415 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 29/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=60; total time=  13.4s\n",
      "[CV 2/5; 29/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1724.4962 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1721.0082 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1718.1001 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 983us/step - loss: 1715.6039 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1713.1766 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1710.7678 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1708.3639 - accuracy: 8.3119e-05 0s - loss: 1709.4401 - accuracy: 0.0 - ETA: 0s - loss: 1709.2345 - accuracy: 1\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 985us/step - loss: 1705.9674 - accuracy: 8.3119e-05 0s - loss: 1707.8918 - accuracy: 9.4162\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1703.5696 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 932us/step - loss: 1701.1740 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 738us/step - loss: 1349.2278 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 29/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=60; total time=  12.7s\n",
      "[CV 3/5; 29/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1574.6370 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 925us/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 885us/step - loss: 1574.6372 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1574.6383 - accuracy: 8.3119e-05 1s - loss: 1595.5760 - \n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 869us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 834us/step - loss: 1574.6387 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 744us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 29/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=60; total time=  11.5s\n",
      "[CV 4/5; 29/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 942us/step - loss: 1605.1025 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 969us/step - loss: 1601.7076 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 933us/step - loss: 1598.6154 - accuracy: 8.3119e-05 1s - loss: 1651.1439 \n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 853us/step - loss: 1596.0293 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1593.5800 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 955us/step - loss: 1591.1648 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 956us/step - loss: 1588.7626 - accuracy: 8.3119e-05 0s - loss: 1593.3121 - accuracy: 0.000\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 952us/step - loss: 1586.3640 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 870us/step - loss: 1583.9664 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 906us/step - loss: 1581.5704 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 873us/step - loss: 1635.4275 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 29/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=60; total time=  11.9s\n",
      "[CV 5/5; 29/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1609.6910 - accuracy: 0.0000e+00A: 1s - loss: 1602.2648 - accuracy - ETA: 0s - loss: 1608.2563 - accuracy: 0.0000 - ETA: 0s - loss: 1609.2063 - accuracy: 0.0000\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1000us/step - loss: 1606.3116 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1603.2007 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 826us/step - loss: 1600.6534 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1598.2146 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1595.8030 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1593.4011 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1591.0022 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 922us/step - loss: 1588.6040 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1586.2104 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 748us/step - loss: 1408.7378 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 29/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=60; total time=  12.0s\n",
      "[CV 1/5; 30/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1585.8572 - accuracy: 1.6624e-04\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1582.4862 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1579.7639 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 975us/step - loss: 1577.2902 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 965us/step - loss: 1574.8679 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1572.4586 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1570.0569 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1567.6567 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 911us/step - loss: 1565.2594 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 989us/step - loss: 1562.8611 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 745us/step - loss: 1698.9867 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 30/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=25; total time=  12.6s\n",
      "[CV 2/5; 30/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0579 - accuracy: 8.3119e-05A: 0s - loss: 1735.9099 - accura\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 990us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 856us/step - loss: 1726.0574 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 905us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 935us/step - loss: 1726.0598 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 938us/step - loss: 1726.0593 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 958us/step - loss: 1726.0582 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0593 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 684us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 30/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=25; total time=  12.2s\n",
      "[CV 3/5; 30/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1574.6365 - accuracy: 8.3119e-05A: 0s - loss: 1573.8071 - accuracy: 1.13 - ETA: 0s - loss: 1575.0068 - accuracy: 8.5324e-0\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 931us/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 859us/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1574.6383 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 842us/step - loss: 1574.6385 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 898us/step - loss: 1574.6377 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1574.6372 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 971us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 896us/step - loss: 1574.6370 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 775us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 30/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=25; total time=  11.6s\n",
      "[CV 4/5; 30/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1604.9808 - accuracy: 1.6624e-04\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1601.7045 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1598.8665 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 827us/step - loss: 1596.3704 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 892us/step - loss: 1593.9425 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1591.5341 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 906us/step - loss: 1589.1322 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 878us/step - loss: 1586.7329 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1584.3341 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 982us/step - loss: 1581.9385 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 804us/step - loss: 1635.8029 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 30/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=25; total time=  11.8s\n",
      "[CV 5/5; 30/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1609.5720 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 988us/step - loss: 1606.2814 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 988us/step - loss: 1603.4438 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 1600.9463 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 933us/step - loss: 1598.5198 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 984us/step - loss: 1596.1122 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 881us/step - loss: 1593.7109 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 999us/step - loss: 1591.3130 - accuracy: 8.3112e-05 0s - loss: 1587.2002 - accurac\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1588.9153 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 1586.5210 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 827us/step - loss: 1409.0538 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 30/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=100, neuron2=25; total time=  12.2s\n",
      "[CV 1/5; 31/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1585.9604 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1582.4993 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1579.4086 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1576.8730 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1574.4343 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 885us/step - loss: 1572.0212 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1569.6183 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 926us/step - loss: 1567.2172 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 863us/step - loss: 1564.8201 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 867us/step - loss: 1562.4242 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 835us/step - loss: 1698.5537 - accuracy: 0.0000e+00 0s - loss: 1750.6384 - accuracy: 0.0000e+0\n",
      "[CV 1/5; 31/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=80; total time=  11.8s\n",
      "[CV 2/5; 31/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1724.5363 - accuracy: 8.3119e-05A: 0s - loss: 1716.0212 - acc\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - ETA: 0s - loss: 1720.2720 - accuracy: 8.6059e-05- ETA: 0s - loss: 1715.1431 - accuracy: 1.09 - 1s 1ms/step - loss: 1721.1196 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1717.9717 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1715.4270 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 915us/step - loss: 1712.9878 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 853us/step - loss: 1710.5756 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1708.1736 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1705.7740 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 884us/step - loss: 1703.3770 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1700.9796 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 745us/step - loss: 1349.0330 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 31/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=80; total time=  12.0s\n",
      "[CV 3/5; 31/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1573.1166 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1569.6807 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1566.5461 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1563.9525 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 857us/step - loss: 1561.5005 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 836us/step - loss: 1559.0865 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 842us/step - loss: 1556.6844 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 912us/step - loss: 1554.2856 - accuracy: 8.3119e-05 0s - loss: 1571.1002 - accuracy - ETA: 0s - loss: 1553.4343 - accuracy: 8.9286e-\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 929us/step - loss: 1551.8894 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 944us/step - loss: 1549.4938 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 822us/step - loss: 1867.9485 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 31/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=80; total time=  12.2s\n",
      "[CV 4/5; 31/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1605.1427 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 928us/step - loss: 1601.6820 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1598.6370 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1596.1139 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 910us/step - loss: 1593.6782 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1591.2668 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 884us/step - loss: 1588.8668 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 829us/step - loss: 1586.4672 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 822us/step - loss: 1584.0708 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 956us/step - loss: 1581.6746 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 778us/step - loss: 1635.5300 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 31/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=80; total time=  11.6s\n",
      "[CV 5/5; 31/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2389 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1611.2389 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 923us/step - loss: 1611.2397 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 948us/step - loss: 1611.2382 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 956us/step - loss: 1611.2379 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 931us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 985us/step - loss: 1611.2377 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 850us/step - loss: 1611.2375 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 1611.2395 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 759us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 31/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=80; total time=  12.2s\n",
      "[CV 1/5; 32/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 980us/step - loss: 1585.9152 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 906us/step - loss: 1582.4406 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1579.5094 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 948us/step - loss: 1577.0084 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 906us/step - loss: 1574.5780 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 933us/step - loss: 1572.1663 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 966us/step - loss: 1569.7648 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 1567.3650 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 910us/step - loss: 1564.9668 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 965us/step - loss: 1562.5685 - accuracy: 8.3119e-05 0s - loss: 1566.1948 - accuracy: 1.063\n",
      "301/301 [==============================] - 0s 801us/step - loss: 1698.6913 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 32/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=60; total time=  12.0s\n",
      "[CV 2/5; 32/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1724.5118 - accuracy: 0.0000e+00A: 0s - loss: 1725.7135 - accuracy: \n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1721.1547 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1718.0601 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 1715.5253 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 869us/step - loss: 1713.0872 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1710.6768 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 891us/step - loss: 1708.2731 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1705.8749 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 967us/step - loss: 1703.4767 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1701.0819 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 848us/step - loss: 1349.1335 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 32/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=60; total time=  12.3s\n",
      "[CV 3/5; 32/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1573.0774 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1569.5988 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1566.6698 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 976us/step - loss: 1564.1669 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1561.7355 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1559.3264 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 857us/step - loss: 1556.9252 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 907us/step - loss: 1554.5270 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 868us/step - loss: 1552.1295 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1549.7362 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 858us/step - loss: 1868.1874 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 32/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=60; total time=  11.9s\n",
      "[CV 4/5; 32/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1605.1072 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 1601.5844 - accuracy: 8.3119e-05 0s - loss: 1591.9943 - accuracy: 1.\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 839us/step - loss: 1598.7203 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1596.2307 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 850us/step - loss: 1593.8032 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1591.3939 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 879us/step - loss: 1588.9918 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 949us/step - loss: 1586.5935 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 958us/step - loss: 1584.1949 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1581.7993 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 779us/step - loss: 1635.6671 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 32/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=60; total time=  11.9s\n",
      "[CV 5/5; 32/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 968us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 946us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 948us/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 918us/step - loss: 1611.2371 - accuracy: 8.3112e-05 1s - loss: 1588.7000 -\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 944us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 948us/step - loss: 1611.2397 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 971us/step - loss: 1611.2384 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 812us/step - loss: 1611.2390 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 755us/step - loss: 1434.9481 - accuracy: 0.0017\n",
      "[CV 5/5; 32/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=60; total time=  12.1s\n",
      "[CV 1/5; 33/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 970us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1587.4758 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 977us/step - loss: 1587.4750 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 838us/step - loss: 1587.4773 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 939us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1587.4758 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1587.4777 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 866us/step - loss: 1587.4750 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 785us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 33/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=25; total time=  11.6s\n",
      "[CV 2/5; 33/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1724.4054 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 983us/step - loss: 1721.1931 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1718.3182 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1715.7758 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 941us/step - loss: 1713.3342 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 858us/step - loss: 1710.9231 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 879us/step - loss: 1708.5179 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 1706.1204 - accuracy: 8.3119e-05 0s - loss: 1699.8961 - accuracy\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 886us/step - loss: 1703.7252 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1701.3301 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 731us/step - loss: 1349.3816 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 33/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=25; total time=  12.1s\n",
      "[CV 3/5; 33/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1572.9979 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 917us/step - loss: 1569.7537 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1566.8009 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 988us/step - loss: 1564.2809 - accuracy: 8.3119e-05 0s - loss: 1566.9960 - accuracy: 1.1\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1561.8467 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 828us/step - loss: 1559.4370 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 842us/step - loss: 1557.0343 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 844us/step - loss: 1554.6362 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 799us/step - loss: 1552.2397 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 1549.8447 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 769us/step - loss: 1868.2977 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 33/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=25; total time=  11.5s\n",
      "[CV 4/5; 33/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6509 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 984us/step - loss: 1606.6492 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1606.6503 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 997us/step - loss: 1606.6490 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 1606.6497 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 851us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1606.6503 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 969us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 983us/step - loss: 1606.6488 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 972us/step - loss: 1606.6511 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 878us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 33/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=25; total time=  12.2s\n",
      "[CV 5/5; 33/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1609.6400 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 956us/step - loss: 1606.2468 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1603.5739 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 952us/step - loss: 1601.1129 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 953us/step - loss: 1598.6917 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 878us/step - loss: 1596.2872 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 832us/step - loss: 1593.8859 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 836us/step - loss: 1591.4861 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1589.0901 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 857us/step - loss: 1586.6959 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 775us/step - loss: 1409.2290 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 33/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=60, neuron2=25; total time=  11.6s\n",
      "[CV 1/5; 34/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 965us/step - loss: 1585.9463 - accuracy: 0.0000e+00\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 836us/step - loss: 1582.4838 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 940us/step - loss: 1579.4122 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 905us/step - loss: 1576.8752 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 937us/step - loss: 1574.4377 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1572.0258 - accuracy: 8.3119e-05 0s - loss: 1573.2131 - accuracy: 1.047\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1569.6215 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 836us/step - loss: 1567.2222 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 815us/step - loss: 1564.8235 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 852us/step - loss: 1562.4265 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 758us/step - loss: 1698.5541 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 34/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=80; total time=  11.4s\n",
      "[CV 2/5; 34/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1724.5448 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 915us/step - loss: 1721.0566 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 831us/step - loss: 1718.0220 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 869us/step - loss: 1715.5050 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 834us/step - loss: 1713.0707 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 853us/step - loss: 1710.6598 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1708.2565 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 854us/step - loss: 1705.8586 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 812us/step - loss: 1703.4624 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 856us/step - loss: 1701.0676 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 837us/step - loss: 1349.1262 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 34/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=80; total time=  11.2s\n",
      "[CV 3/5; 34/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 839us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 846us/step - loss: 1574.6377 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 871us/step - loss: 1574.6392 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 932us/step - loss: 1574.6390 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 922us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 929us/step - loss: 1574.6383 - accuracy: 8.3119e-05 0s - loss: 1572.7789 - accuracy: 9.960\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 863us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 765us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 34/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=80; total time=  11.5s\n",
      "[CV 4/5; 34/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1605.1439 - accuracy: 1.6624e-04A: 0s - loss: 1608.1891 - accuracy: 2.006\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 929us/step - loss: 1601.5901 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 951us/step - loss: 1598.6377 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 1596.1333 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 861us/step - loss: 1593.7017 - accuracy: 8.3119e-05 0s - loss: 1630.3898 - accura\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 840us/step - loss: 1591.2914 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 869us/step - loss: 1588.8896 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 820us/step - loss: 1586.4911 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 945us/step - loss: 1584.0947 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 913us/step - loss: 1581.6986 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - ETA: 0s - loss: 1656.0601 - accuracy: 0.0000e+0 - 0s 834us/step - loss: 1635.5590 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 34/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=80; total time=  11.6s\n",
      "[CV 5/5; 34/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1609.7279 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.2986 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1603.1544 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 1600.6034 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 933us/step - loss: 1598.1628 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 923us/step - loss: 1595.7501 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 904us/step - loss: 1593.3494 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 849us/step - loss: 1590.9496 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1588.5530 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 848us/step - loss: 1586.1576 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 754us/step - loss: 1408.6863 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 34/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=80; total time=  11.9s\n",
      "[CV 1/5; 35/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1585.9443 - accuracy: 0.0000e+00A: 0s - loss: 1592.0171 - acc\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1582.4520 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1579.5023 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 832us/step - loss: 1576.9966 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 982us/step - loss: 1574.5648 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 958us/step - loss: 1572.1538 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 999us/step - loss: 1569.7511 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 948us/step - loss: 1567.3507 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1564.9525 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 926us/step - loss: 1562.5564 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 751us/step - loss: 1698.6752 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 35/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=60; total time=  12.2s\n",
      "[CV 2/5; 35/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 3s 1ms/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 970us/step - loss: 1726.0605 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 960us/step - loss: 1726.0577 - accuracy: 8.3119e-05 1s - loss: 1708.0039 - a\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 987us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 901us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 926us/step - loss: 1726.0571 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 954us/step - loss: 1726.0607 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 941us/step - loss: 1726.0601 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 930us/step - loss: 1726.0583 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 718us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 35/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=60; total time=  13.5s\n",
      "[CV 3/5; 35/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 948us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 957us/step - loss: 1574.6383 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6372 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 971us/step - loss: 1574.6388 - accuracy: 8.3119e-05 0s - loss: 1561.5383 - accur\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 925us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 827us/step - loss: 1574.6368 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 831us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 828us/step - loss: 1574.6383 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 865us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 826us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 35/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=60; total time=  11.7s\n",
      "[CV 4/5; 35/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 913us/step - loss: 1605.1150 - accuracy: 1.6624e-04\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 833us/step - loss: 1601.7227 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 809us/step - loss: 1598.5925 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 866us/step - loss: 1596.0316 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 1593.5884 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 890us/step - loss: 1591.1742 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 877us/step - loss: 1588.7697 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 883us/step - loss: 1586.3735 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 903us/step - loss: 1583.9747 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 990us/step - loss: 1581.5790 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 918us/step - loss: 1635.4429 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 35/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=60; total time=  11.4s\n",
      "[CV 5/5; 35/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 979us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 879us/step - loss: 1611.2397 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 908us/step - loss: 1611.2385 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 899us/step - loss: 1611.2397 - accuracy: 8.3112e-05 0s - loss: 1609.5199 - accuracy: 1.1\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 922us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1611.2394 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1611.2386 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 913us/step - loss: 1611.2382 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 979us/step - loss: 1611.2377 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1611.2380 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 786us/step - loss: 1434.9481 - accuracy: 0.0017 ETA: 0s - loss: 1149.4832 - accuracy: 0.0000e\n",
      "[CV 5/5; 35/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=60; total time=  11.7s\n",
      "[CV 1/5; 36/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 989us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 996us/step - loss: 1587.4755 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 866us/step - loss: 1587.4777 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1587.4768 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 844us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 881us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 871us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 886us/step - loss: 1587.4766 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 860us/step - loss: 1587.4753 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 839us/step - loss: 1587.4752 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 857us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 36/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=25; total time=  11.4s\n",
      "[CV 2/5; 36/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0605 - accuracy: 8.3119e-05A: 0s - loss: 1702.1342 - ac\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 885us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 815us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 969us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 936us/step - loss: 1726.0616 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 971us/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 969us/step - loss: 1726.0580 - accuracy: 8.3119e-05 1s - loss: 1711.6578 -\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1726.0601 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 881us/step - loss: 1726.0570 - accuracy: 8.3119e-05 0s - loss: 1721.0892 - accuracy: 0\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 820us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 894us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 36/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=25; total time=  11.7s\n",
      "[CV 3/5; 36/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 939us/step - loss: 1573.0277 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 824us/step - loss: 1569.6631 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 809us/step - loss: 1566.8433 - accuracy: 8.3119e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 807us/step - loss: 1564.3552 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 822us/step - loss: 1561.9280 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 821us/step - loss: 1559.5189 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 797us/step - loss: 1557.1183 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1554.7196 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 871us/step - loss: 1552.3230 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 871us/step - loss: 1549.9292 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 850us/step - loss: 1868.3823 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 36/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=25; total time=  10.8s\n",
      "[CV 4/5; 36/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1606.6509 - accuracy: 8.3119e-05A: 1s - loss: 1605.1835 - accura - ETA: 0s - loss: 1613.5846 - accuracy: 1.05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1606.6509 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 863us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 900us/step - loss: 1606.6501 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 876us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 888us/step - loss: 1606.6505 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 899us/step - loss: 1606.6484 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 888us/step - loss: 1606.6495 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 887us/step - loss: 1606.6498 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 748us/step - loss: 1661.7108 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 36/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=25; total time=  11.9s\n",
      "[CV 5/5; 36/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1609.6222 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 985us/step - loss: 1606.2855 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 944us/step - loss: 1603.4532 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 951us/step - loss: 1600.9573 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 980us/step - loss: 1598.5291 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 987us/step - loss: 1596.1205 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 965us/step - loss: 1593.7197 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1591.3215 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 963us/step - loss: 1588.9236 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1586.5286 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 811us/step - loss: 1409.0592 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 36/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.001, neuron1=30, neuron2=25; total time=  12.4s\n",
      "[CV 1/5; 37/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4753 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4766 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 947us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 836us/step - loss: 1587.4753 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 845us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 835us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 880us/step - loss: 1587.4758 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 873us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 844us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 779us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 37/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=80; total time=  11.8s\n",
      "[CV 2/5; 37/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 967us/step - loss: 1710.4926 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 881us/step - loss: 1684.6414 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 859us/step - loss: 1660.8247 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 902us/step - loss: 1637.4005 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1614.2158 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 942us/step - loss: 1591.1591 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 940us/step - loss: 1568.2145 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 969us/step - loss: 1545.4235 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1522.8462 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1500.5596 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 783us/step - loss: 1132.1721 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 37/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=80; total time=  11.7s\n",
      "[CV 3/5; 37/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1574.6372 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1574.6388 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 965us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1574.6376 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 859us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 850us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 871us/step - loss: 1574.6377 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 866us/step - loss: 1574.6382 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 867us/step - loss: 1574.6378 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 854us/step - loss: 1894.2913 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 37/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=80; total time=  11.9s\n",
      "[CV 4/5; 37/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1591.5383 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1566.2468 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1542.5085 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 987us/step - loss: 1519.0546 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 972us/step - loss: 1495.7703 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1472.5922 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 908us/step - loss: 1449.5786 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1426.7504 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1404.2136 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 990us/step - loss: 1381.9728 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 806us/step - loss: 1425.5693 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 37/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=80; total time=  12.6s\n",
      "[CV 5/5; 37/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=80\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 987us/step - loss: 1596.2706 - accuracy: 8.3112e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1571.0892 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 928us/step - loss: 1547.2747 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 945us/step - loss: 1523.7512 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 997us/step - loss: 1500.3925 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 992us/step - loss: 1477.1237 - accuracy: 8.3112e-05 0s - loss: 1452.7108 - \n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 996us/step - loss: 1454.0470 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1431.2391 - accuracy: 8.3112e-05A: 0s - loss: 1432.5151 - accuracy: 1\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1408.6903 - accuracy: 8.3112e-05A: 0s - loss: 1409.9919 - accuracy: 0.000\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 916us/step - loss: 1386.4327 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 863us/step - loss: 1203.0042 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 37/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=80; total time=  12.9s\n",
      "[CV 1/5; 38/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1587.4771 - accuracy: 8.3119e-05A: 1s - loss: 1588.2307 - accu\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 921us/step - loss: 1587.4758 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 970us/step - loss: 1587.4755 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 923us/step - loss: 1587.4773 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 947us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4761 - accuracy: 8.3119e-05A: 1s - loss: 1602.4879 - accura\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 974us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4762 - accuracy: 8.3119e-05A: 0s - loss: 1593.8999 - accuracy: \n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 875us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 945us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 839us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 38/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=60; total time=  12.8s\n",
      "[CV 2/5; 38/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0577 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0590 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 965us/step - loss: 1726.0603 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 951us/step - loss: 1726.0582 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 935us/step - loss: 1726.0592 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 935us/step - loss: 1726.0601 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 934us/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 982us/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 889us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 38/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=60; total time=  12.4s\n",
      "[CV 3/5; 38/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1559.7458 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1534.6448 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1510.9535 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1487.6008 - accuracy: 8.3119e-05A: 0s - loss: 1485.8831 - accuracy: 8.9606\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1464.4379 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1441.3723 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1418.4214 - accuracy: 8.3119e-05A: 0s - loss: 1418.9323 - accuracy: 0. - ETA: 0s - loss: 1421.3673 - accuracy: 1.0\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1395.6277 - accuracy: 8.3119e-05A: 0s - loss: 1395.5431 - accuracy: 1.05\n",
      "Epoch 9/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1373.0059 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1350.5953 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 761us/step - loss: 1659.8324 - accuracy: 0.0000e+00\n",
      "[CV 3/5; 38/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=60; total time=  15.7s\n",
      "[CV 4/5; 38/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1591.2396 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1565.6145 - accuracy: 8.3119e-05A: 0s - loss: 1569.5691 - acc\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1541.8475 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1518.3937 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 864us/step - loss: 1495.1010 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1471.9152 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 859us/step - loss: 1448.8932 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 845us/step - loss: 1426.0968 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 831us/step - loss: 1403.5742 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 939us/step - loss: 1381.3474 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 961us/step - loss: 1424.9218 - accuracy: 0.0000e+00\n",
      "[CV 4/5; 38/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=60; total time=  12.1s\n",
      "[CV 5/5; 38/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=60\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 1ms/step - loss: 1596.1173 - accuracy: 8.3112e-05A: 0s - loss: 1594.3862 - accuracy: 1.05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 943us/step - loss: 1570.7780 - accuracy: 8.3112e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 959us/step - loss: 1546.9423 - accuracy: 8.3112e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 984us/step - loss: 1523.4199 - accuracy: 8.3112e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1500.0565 - accuracy: 8.3112e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 893us/step - loss: 1476.8004 - accuracy: 8.3112e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 962us/step - loss: 1453.7184 - accuracy: 8.3112e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1430.9087 - accuracy: 8.3112e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 909us/step - loss: 1408.4050 - accuracy: 8.3112e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 924us/step - loss: 1386.1582 - accuracy: 8.3112e-05\n",
      "301/301 [==============================] - 0s 812us/step - loss: 1202.7155 - accuracy: 0.0000e+00\n",
      "[CV 5/5; 38/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=60; total time=  12.5s\n",
      "[CV 1/5; 39/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 1s 934us/step - loss: 1587.4767 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4768 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 941us/step - loss: 1587.4767 - accuracy: 8.3119e-05 0s - loss: 1584.3008 - accu\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 882us/step - loss: 1587.4761 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 914us/step - loss: 1587.4752 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 834us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 804us/step - loss: 1587.4763 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 849us/step - loss: 1587.4771 - accuracy: 8.3119e-05\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1587.4767 - accuracy: 8.3119e-05A: 0s - loss: 1589.8030 - accuracy: 1.\n",
      "301/301 [==============================] - 0s 869us/step - loss: 1724.7826 - accuracy: 0.0000e+00\n",
      "[CV 1/5; 39/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=25; total time=  12.2s\n",
      "[CV 2/5; 39/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 984us/step - loss: 1726.0593 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0580 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 976us/step - loss: 1726.0603 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0587 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 1ms/step - loss: 1726.0582 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 998us/step - loss: 1726.0605 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 931us/step - loss: 1726.0580 - accuracy: 8.3119e-05 1s - loss: 1783.6827 \n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 952us/step - loss: 1726.0601 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      "1204/1204 [==============================] - 1s 999us/step - loss: 1726.0590 - accuracy: 8.3119e-05 1s - loss: 1771.9236 - accuracy: 0.0000e+ - ETA: 1s - loss: 1778.0353 -\n",
      "Epoch 10/10\n",
      "1204/1204 [==============================] - 1s 952us/step - loss: 1726.0597 - accuracy: 8.3119e-05\n",
      "301/301 [==============================] - 0s 893us/step - loss: 1375.3484 - accuracy: 0.0000e+00\n",
      "[CV 2/5; 39/8748] END activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=25; total time=  12.7s\n",
      "[CV 3/5; 39/8748] START activation_function=softmax, batch_size=10, dropout_rate=0.0, epochs=10, init=normal, learning_rate=0.01, neuron1=100, neuron2=25\n",
      "Epoch 1/10\n",
      "1204/1204 [==============================] - 2s 962us/step - loss: 1560.2328 - accuracy: 8.3119e-05\n",
      "Epoch 2/10\n",
      "1204/1204 [==============================] - 1s 919us/step - loss: 1535.4575 - accuracy: 8.3119e-05\n",
      "Epoch 3/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1511.7794 - accuracy: 8.3119e-05\n",
      "Epoch 4/10\n",
      "1204/1204 [==============================] - 1s 911us/step - loss: 1488.4021 - accuracy: 8.3119e-05\n",
      "Epoch 5/10\n",
      "1204/1204 [==============================] - 1s 895us/step - loss: 1465.2330 - accuracy: 8.3119e-05\n",
      "Epoch 6/10\n",
      "1204/1204 [==============================] - 1s 923us/step - loss: 1442.1650 - accuracy: 8.3119e-05\n",
      "Epoch 7/10\n",
      "1204/1204 [==============================] - 1s 910us/step - loss: 1419.2056 - accuracy: 8.3119e-05\n",
      "Epoch 8/10\n",
      "1204/1204 [==============================] - 1s 955us/step - loss: 1396.4281 - accuracy: 8.3119e-05\n",
      "Epoch 9/10\n",
      " 657/1204 [===============>..............] - ETA: 0s - loss: 1373.7842 - accuracy: 0.0000e+00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-71-94c9c4309a34>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgrid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mparam_grid\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparam_grids\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mgrid_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgrid\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_scaled\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    839\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    840\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 841\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    842\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m             \u001b[1;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1286\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1287\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1288\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1289\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1290\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    793\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    796\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1043\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1044\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1045\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1046\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    857\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 859\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    860\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    861\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    775\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 777\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    778\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    779\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    220\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 222\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    591\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    594\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    230\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Invalid shape for y: '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    231\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 232\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    233\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m     \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1206\u001b[0m         \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_epoch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1207\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_stop_iteration\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1208\u001b[1;33m           \u001b[1;32mfor\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1209\u001b[0m             with tf.profiler.experimental.Trace(\n\u001b[0;32m   1210\u001b[0m                 \u001b[1;34m'train'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py\u001b[0m in \u001b[0;36msteps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1248\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_insufficient_data\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# Set by `catch_stop_iteration`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m         \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m       \u001b[0moriginal_spe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_steps_per_execution\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1251\u001b[0m       can_run_full_execution = (\n\u001b[0;32m   1252\u001b[0m           \u001b[0moriginal_spe\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    643\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    644\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 645\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_value\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    646\u001b[0m     raise NotImplementedError(\n\u001b[0;32m    647\u001b[0m         \"numpy() is only available when eager execution is enabled.\")\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_value\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    718\u001b[0m     \"\"\"\n\u001b[0;32m    719\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Read\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 720\u001b[1;33m       \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_read_variable_op\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    721\u001b[0m     \u001b[1;31m# Return an identity so it can get placed on whatever device the context\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    722\u001b[0m     \u001b[1;31m# specifies instead of the device where the variable is.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36m_read_variable_op\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    697\u001b[0m           \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py\u001b[0m in \u001b[0;36mread_and_set_handle\u001b[1;34m()\u001b[0m\n\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mread_and_set_handle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 689\u001b[1;33m       result = gen_resource_variable_ops.read_variable_op(\n\u001b[0m\u001b[0;32m    690\u001b[0m           self.handle, self._dtype)\n\u001b[0;32m    691\u001b[0m       \u001b[0m_maybe_set_handle_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mread_variable_op\u001b[1;34m(resource, dtype, name)\u001b[0m\n\u001b[0;32m    467\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mtld\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_eager\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    468\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 469\u001b[1;33m       _result = pywrap_tfe.TFE_Py_FastPathExecute(\n\u001b[0m\u001b[0;32m    470\u001b[0m         _ctx, \"ReadVariableOp\", name, resource, \"dtype\", dtype)\n\u001b[0;32m    471\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Build and fit the GridSearchCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "grid = GridSearchCV(estimator = model,param_grid = param_grids,cv = 5,verbose = 10)\n",
    "grid_result = grid.fit(X_scaled,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf517ff2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
